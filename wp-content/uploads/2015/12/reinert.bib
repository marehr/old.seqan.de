%% Created using Papers on Fri, 18 Dec 2015.
%% http://papersapp.com/papers/

@article{Reinert:2015ds,
author = {Reinert, Knut and Langmead, Ben and Weese, David and Evers, Dirk J},
title = {{Alignment of Next-Generation Sequencing Reads.}},
journal = {Annual review of genomics and human genetics},
year = {2015},
volume = {16},
pages = {133--151},
month = aug,
affiliation = {Department of Mathematics and Computer Science, Freie Universit{\"a}t Berlin, 14195 Berlin, Germany; email: knut.reinert@fu-berlin.de , david.weese@fu-berlin.de.},
doi = {10.1146/annurev-genom-090413-025358},
pmid = {25939052},
language = {English},
read = {Yes},
rating = {0},
date-added = {2015-09-08T22:46:25GMT},
date-modified = {2015-11-26T15:38:48GMT},
abstract = {High-throughput DNA sequencing has considerably changed the possibilities for conducting biomedical research by measuring billions of short DNA or RNA fragments. A central computational problem, and for many applications a first step, consists of determining where the fragments came from in the original genome. In this article, we review the main techniques for generating the fragments, the main applications, and the main algorithmic ideas for computing a solution to the read alignment problem. In addition, we describe pitfalls and difficulties connected to determining the correct positions of reads.},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=25939052&retmode=ref&cmd=prlinks},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Files/75/7559E08C-FEF5-4C6C-8B06-256C0CF662A7},
file = {{7559E08C-FEF5-4C6C-8B06-256C0CF662A7:/Users/reinert/Dropbox/Library.papers3/Files/75/7559E08C-FEF5-4C6C-8B06-256C0CF662A7:application/pdf;7559E08C-FEF5-4C6C-8B06-256C0CF662A7:/Users/reinert/Dropbox/Library.papers3/Files/75/7559E08C-FEF5-4C6C-8B06-256C0CF662A7:application/pdf}},
uri = {\url{papers3://publication/doi/10.1146/annurev-genom-090413-025358}}
}

@article{Holtgrewe:2015bna,
author = {Holtgrewe, Manuel and Kuchenbecker, Leon and Reinert, Knut},
title = {{Methods for the detection and assembly of novel sequence in high-throughput sequencing data.}},
journal = {Bioinformatics (Oxford, England)},
year = {2015},
volume = {31},
number = {12},
pages = {1904--1912},
month = jun,
publisher = {Oxford University Press},
affiliation = {Department of Computer Science, Freie Universit{\"a}t Berlin and Max Planck Institute for Molecular Genetics, Berlin, Germany.},
doi = {10.1093/bioinformatics/btv051},
pmid = {25649620},
language = {English},
read = {Yes},
rating = {0},
date-added = {2015-11-11T13:51:39GMT},
date-modified = {2015-12-08T08:15:01GMT},
abstract = {MOTIVATION:Large insertions of novel sequence are an important type of structural variants. Previous studies used traditional de novo assemblers for assembling non-mapping high-throughput sequencing (HTS) or capillary reads and then tried to anchor them in the reference using paired read information.

RESULTS:We present approaches for detecting insertion breakpoints and targeted assembly of large insertions from HTS paired data: BASIL and ANISE. On near identity repeats that are hard for assemblers, ANISE employs a repeat resolution step. This results in far better reconstructions than obtained by the compared methods. On simulated data, we found our insert assembler to be competitive with the de novo assemblers ABYSS and SGA while yielding already anchored inserted sequence as opposed to unanchored contigs as from ABYSS/SGA. On real-world data, we detected novel sequence in a human individual and thoroughly validated the assembled sequence. ANISE was found to be superior to the competing tool MindTheGap on both simulated and real-world data.

AVAILABILITY AND IMPLEMENTATION:ANISE and BASIL are available for download at http://www.seqan.de/projects/herbarium under a permissive open source license.},
url = {http://bioinformatics.oxfordjournals.org/content/31/12/1904.full},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Files/28/28042B27-15F4-4BEC-A9DB-B1D0A22E6000},
file = {{28042B27-15F4-4BEC-A9DB-B1D0A22E6000:/Users/reinert/Dropbox/Library.papers3/Files/28/28042B27-15F4-4BEC-A9DB-B1D0A22E6000:application/pdf;28042B27-15F4-4BEC-A9DB-B1D0A22E6000:/Users/reinert/Dropbox/Library.papers3/Files/28/28042B27-15F4-4BEC-A9DB-B1D0A22E6000:application/pdf}},
uri = {\url{papers3://publication/doi/10.1093/bioinformatics/btv051}}
}

@article{Schultz:2015gq,
author = {Schultz, Luise and Zurich, Marie-Gabrielle and Culot, Maxime and da Costa, Anaelle and Landry, Christophe and Bellwon, Patricia and Kristl, Theresa and H{\"o}rmann, Katrin and Ruzek, Silke and Aiche, Stephan and Reinert, Knut and Bielow, Chris and Gosselet, Fabien and Cecchelli, Romeo and Huber, Christian G and Schroeder, Olaf H-U and Gramowski-Voss, Alexandra and Weiss, Dieter G and Bal-Price, Anna},
title = {{Evaluation of drug-induced neurotoxicity based on metabolomics, proteomics and electrical activity measurements in complementary CNS in vitro models.}},
journal = {Toxicology in vitro : an international journal published in association with BIBRA},
year = {2015},
month = may,
affiliation = {Department of Animal Physiology, Institute of Biological Sciences, University of Rostock, D-18051 Rostock, Germany.},
doi = {10.1016/j.tiv.2015.05.016},
pmid = {26026931},
language = {English},
rating = {0},
date-added = {2015-09-08T22:48:44GMT},
date-modified = {2015-11-26T15:38:48GMT},
abstract = {The present study was performed in an attempt to develop an in vitro integrated testing strategy (ITS) to evaluate drug-induced neurotoxicity. A number of endpoints were analyzed using two complementary brain cell culture models and an in vitro blood-brain barrier (BBB) model after single and repeated exposure treatments with selected drugs that covered the major biological, pharmacological and neuro-toxicological responses. Furthermore, four drugs (diazepam, cyclosporine A, chlorpromazine and amiodarone) were tested more in depth as representatives of different classes of neurotoxicants, inducing toxicity through different pathways of toxicity. The developed in vitro BBB model allowed detection of toxic effects at the level of BBB and evaluation of drug transport through the barrier for predicting free brain concentrations of the studied drugs. The measurement of neuronal electrical activity was found to be a sensitive tool to predict the neuroactivity and neurotoxicity of drugs after acute exposure. The histotypic 3D re-aggregating brain cell cultures, containing all brain cell types, were found to be well suited for OMICs analyses after both acute and long term treatment. The obtained data suggest that an in vitro ITS based on the information obtained from BBB studies and combined with metabolomics, proteomics and neuronal electrical activity measurements performed in stable in vitro neuronal cell culture systems, has high potential to improve current in vitro drug-induced neurotoxicity evaluation.},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=26026931&retmode=ref&cmd=prlinks},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Files/7F/7FF7D0E1-9745-45A8-991C-5846A91653B6},
file = {{7FF7D0E1-9745-45A8-991C-5846A91653B6:/Users/reinert/Dropbox/Library.papers3/Files/7F/7FF7D0E1-9745-45A8-991C-5846A91653B6:application/pdf}},
uri = {\url{papers3://publication/doi/10.1016/j.tiv.2015.05.016}}
}

@article{Kuchenbecker:2015kz,
author = {Kuchenbecker, Leon and Nienen, Mikalai and Hecht, Jochen and Neumann, Avidan U and Babel, Nina and Reinert, Knut and Robinson, Peter N},
title = {{IMSEQ - a fast and error aware approach to immunogenetic sequence analysis}},
journal = {Bioinformatics (Oxford, England)},
year = {2015},
volume = {31},
number = {18},
pages = {btv309--2971},
month = may,
publisher = {Oxford University Press},
affiliation = {Berlin-Brandenburg Center for Regenerative Therapies, Charit{\'e} Universit{\"a}tsmedizin, Berlin, Department of Computer Science, Freie Universit{\"a}t, Berlin, Max Planck Institute for Molecular Genetics, Ihnestrasse 63-73, 14195 Berlin, Germany, Goodman Faculty of Life Sciences, Bar-Ilan University, Ramat Gan, Israel, Marien Hospital Herne, Ruhr University Bochum, Bochum and Institute of Medical Genetics and Human Genetics, Charit{\'e} Universit{\"a}tsmedizin Berlin, Berlin, Germany Berlin-Brandenburg Center for Regenerative Therapies, Charit{\'e} Universit{\"a}tsmedizin, Berlin, Department of Computer Science, Freie Universit{\"a}t, Berlin, Max Planck Institute for Molecular Genetics, Ihnestrasse 63-73, 14195 Berlin, Germany, Goodman Faculty of Life Sciences, Bar-Ilan University, Ramat Gan, Israel, Marien Hospital Herne, Ruhr University Bochum, Bochum and Institute of Medical Genetics and Human Genetics, Charit{\'e} Universit{\"a}tsmedizin Berlin, Berlin, Germany Berlin-Brandenburg Center for Regenerative Therapies, Charit{\'e} Universit{\"a}tsmedizin, Berlin, Department of Computer Science, Freie Universit{\"a}t, Berlin, Max Planck Institute for Molecular Genetics, Ihnestrasse 63-73, 14195 Berlin, Germany, Goodman Faculty of Life Sciences, Bar-Ilan University, Ramat Gan, Israel, Marien Hospital Herne, Ruhr University Bochum, Bochum and Institute of Medical Genetics and Human Genetics, Charit{\'e} Universit{\"a}tsmedizin Berlin, Berlin, Germany.},
doi = {10.1093/bioinformatics/btv309},
pmid = {25987567},
language = {English},
read = {Yes},
rating = {0},
date-added = {2015-09-10T13:08:52GMT},
date-modified = {2015-11-27T14:07:54GMT},
abstract = {Abstract Motivation: Recombined T and B cell receptor repertoires are increasingly being studied using next generation sequencing (NGS) in order to interrogate the repertoire composition as well as changes in the distribution of receptor clones under different ... 
},
url = {http://bioinformatics.oxfordjournals.org/lookup/doi/10.1093/bioinformatics/btv309},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Files/6A/6A37250E-2353-4A74-B15E-9B2E1287153F},
file = {{6A37250E-2353-4A74-B15E-9B2E1287153F:/Users/reinert/Dropbox/Library.papers3/Files/6A/6A37250E-2353-4A74-B15E-9B2E1287153F:application/pdf}},
uri = {\url{papers3://publication/doi/10.1093/bioinformatics/btv309}}
}

@techreport{Canzar:2015cq,
author = {Canzar, Stefan and Andreotti, Sandro and Weese, David and Reinert, Knut and Klau, Gunnar W},
title = {{CIDANE: Comprehensive isoform discovery and abundance estimation}},
year = {2015},
month = apr,
doi = {10.1101/017939},
read = {Yes},
rating = {0},
date-added = {2015-04-13T09:47:25GMT},
date-modified = {2015-11-27T14:08:05GMT},
url = {http://biorxiv.org/lookup/doi/10.1101/017939},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Files/82/82C0A171-9A1B-4B2A-A7BF-5CA75582433A.pdf},
file = {{82C0A171-9A1B-4B2A-A7BF-5CA75582433A.pdf:/Users/reinert/Dropbox/Library.papers3/Files/82/82C0A171-9A1B-4B2A-A7BF-5CA75582433A.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1101/017939}}
}

@article{Hu:2015ev,
author = {Hu, Jialu and Reinert, Knut},
title = {{LocalAli: an evolutionary-based local alignment approach to identify functionally conserved modules in multiple networks}},
journal = {Bioinformatics (Oxford, England)},
year = {2015},
volume = {31},
number = {3},
pages = {363--372},
month = feb,
publisher = {Oxford University Press},
doi = {10.1093/bioinformatics/btu652},
pmid = {25282642},
language = {English},
read = {Yes},
rating = {0},
date-added = {2015-12-08T07:53:16GMT},
date-modified = {2015-12-18T13:30:00GMT},
abstract = {Abstract Motivation: Sequences and protein interaction data are of significance to understand the underlying molecular mechanism of organisms. Local network alignment is one of key systematic ways for predicting protein functions, identifying functional modules ...
},
url = {http://bioinformatics.oxfordjournals.org/content/31/3/363.full},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Files/28/28906EC0-6AEA-443D-AFD0-94A4ACEB0186},
file = {{28906EC0-6AEA-443D-AFD0-94A4ACEB0186:/Users/reinert/Dropbox/Library.papers3/Files/28/28906EC0-6AEA-443D-AFD0-94A4ACEB0186:application/pdf}},
uri = {\url{papers3://publication/doi/10.1093/bioinformatics/btu652}}
}

@article{Aiche:2015fq,
author = {Aiche, Stephan and Sachsenberg, Timo and Kenar, Erhan and Walzer, Mathias and Wiswedel, Bernd and Kristl, Theresa and Boyles, Matthew and Duschl, Albert and Huber, Christian G and Berthold, Michael R and Reinert, Knut and Kohlbacher, Oliver},
title = {{Workflows for automated downstream data analysis and visualization in large-scale computational mass spectrometry}},
journal = {Proteomics},
year = {2015},
month = jan,
doi = {10.1002/pmic.201400391},
pmid = {25604327},
pmcid = {PMC4415483},
language = {English},
read = {Yes},
rating = {0},
date-added = {2015-02-10T10:34:16GMT},
date-modified = {2015-12-11T16:07:17GMT},
abstract = {Abstract Mass spectrometry-based proteomics and metabolomics are rapidly evolving research fields driven by the development of novel instruments, experimental approaches, and analysis methods. Monolithic analysis tools perform well on single tasks but lack the ... 
},
url = {http://onlinelibrary.wiley.com/doi/10.1002/pmic.201400391/abstract},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Files/3A/3ADDBC25-4EB7-4EFB-8E02-D54D26C98F1E},
file = {{3ADDBC25-4EB7-4EFB-8E02-D54D26C98F1E:/Users/reinert/Dropbox/Library.papers3/Files/3A/3ADDBC25-4EB7-4EFB-8E02-D54D26C98F1E:application/pdf}},
uri = {\url{papers3://publication/doi/10.1002/pmic.201400391}}
}

@article{Neu:2014iz,
author = {Neu, Volker and Bielow, Chris and Reinert, Knut and Huber, Christian G},
title = {{Ultrahigh-performance liquid chromatography-ultraviolet absorbance detection-high-resolution-mass spectrometry combined with automated data processing for studying the kinetics of oxidative thermal degradation of thyroxine in the solid state}},
journal = {Journal of chromatography. A},
year = {2014},
volume = {1371},
pages = {196--203},
month = dec,
doi = {10.1016/j.chroma.2014.10.071},
pmid = {25456598},
language = {English},
read = {Yes},
rating = {0},
date-added = {2014-11-19T14:51:51GMT},
date-modified = {2015-08-26T09:08:53GMT},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0021967314016823},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Files/BA/BA2E6EA3-6D29-47DE-9950-2C6CCFB78153},
file = {{BA2E6EA3-6D29-47DE-9950-2C6CCFB78153:/Users/reinert/Dropbox/Library.papers3/Files/BA/BA2E6EA3-6D29-47DE-9950-2C6CCFB78153:application/pdf;BA2E6EA3-6D29-47DE-9950-2C6CCFB78153:/Users/reinert/Dropbox/Library.papers3/Files/BA/BA2E6EA3-6D29-47DE-9950-2C6CCFB78153:application/pdf}},
uri = {\url{papers3://publication/doi/10.1016/j.chroma.2014.10.071}}
}

@article{Schulz:2014dm,
author = {Schulz, Marcel H and Weese, David and Holtgrewe, Manuel and Dimitrova, V and Niu, Sijia and Reinert, Knut and Richard, Hugues},
title = {{Fiona: a parallel and automatic strategy for read error correction.}},
journal = {Bioinformatics (Oxford, England)},
year = {2014},
volume = {30},
number = {17},
pages = {i356--i363},
month = sep,
publisher = {Oxford University Press},
affiliation = {'Multimodal Computing and Interaction', Saarland University {\&} Department for Computational Biology and Applied Computing, Max Planck Institute for Informatics, Saarbr{\"u}cken, 66123 Saarland, Germany, Ray and Stephanie Lane Center for Computational Biology, Carnegie Mellon University, Pittsburgh, 15206 PA, USA, Department of Mathematics and Computer Science, Freie Universit{\"a}t Berlin, 14195 Berlin, Germany, Universit{\'e} Pierre et Marie Curie, UMR7238, CNRS-UPMC, Paris, France and CNRS, UMR7238, Laboratory of Computational and Quantitative Biology, Paris, France 'Multimodal Computing and Interaction', Saarland University {\&} Department for Computational Biology and Applied Computing, Max Planck Institute for Informatics, Saarbr{\"u}cken, 66123 Saarland, Germany, Ray and Stephanie Lane Center for Computational Biology, Carnegie Mellon University, Pittsburgh, 15206 PA, USA, Department of Mathematics and Computer Science, Freie Universit{\"a}t Berlin, 14195 Berlin, Germany, Universit{\'e} Pierre et Marie Curie, UMR7238, CNRS-UPMC, Paris, France and CNRS, UMR7238, Laboratory of Computational and Quantitative Biology, Paris, France.},
doi = {10.1093/bioinformatics/btu440},
pmid = {25161220},
pmcid = {PMC4147893},
language = {English},
read = {Yes},
rating = {0},
date-added = {2014-09-08T12:32:23GMT},
date-modified = {2015-11-27T14:08:06GMT},
abstract = {MOTIVATION:Automatic error correction of high-throughput sequencing data can have a dramatic impact on the amount of usable base pairs and their quality. It has been shown that the performance of tasks such as de novo genome assembly and SNP calling can be dramatically improved after read error correction. While a large number of methods specialized for correcting substitution errors as found in Illumina data exist, few methods for the correction of indel errors, common to technologies like 454 or Ion Torrent, have been proposed.

RESULTS:We present Fiona, a new stand-alone read error-correction method. Fiona provides a new statistical approach for sequencing error detection and optimal error correction and estimates its parameters automatically. Fiona is able to correct substitution, insertion and deletion errors and can be applied to any sequencing technology. It uses an efficient implementation of the partial suffix array to detect read overlaps with different seed lengths in parallel. We tested Fiona on several real datasets from a variety of organisms with different read lengths and compared its performance with state-of-the-art methods. Fiona shows a constantly higher correction accuracy over a broad range of datasets from 454 and Ion Torrent sequencers, without compromise in speed.

CONCLUSION:Fiona is an accurate parameter-free read error-correction method that can be run on inexpensive hardware and can make use of multicore parallelization whenever available. Fiona was implemented using the SeqAn library for sequence analysis and is publicly available for download at http://www.seqan.de/projects/fiona.

CONTACT:mschulz@mmci.uni-saarland.de or hugues.richard@upmc.fr

SUPPLEMENTARY INFORMATION:Supplementary data are available at Bioinformatics online.},
url = {http://bioinformatics.oxfordjournals.org/content/30/17/i356.full},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Files/75/75795684-ABC8-488D-BB7B-330F2F28B93C},
file = {{75795684-ABC8-488D-BB7B-330F2F28B93C:/Users/reinert/Dropbox/Library.papers3/Files/75/75795684-ABC8-488D-BB7B-330F2F28B93C:application/pdf;75795684-ABC8-488D-BB7B-330F2F28B93C:/Users/reinert/Dropbox/Library.papers3/Files/75/75795684-ABC8-488D-BB7B-330F2F28B93C:application/pdf}},
uri = {\url{papers3://publication/doi/10.1093/bioinformatics/btu440}}
}

@article{Hauswedell:2014bt,
author = {Hauswedell, Hannes and Singer, Jochen and Reinert, Knut},
title = {{Lambda: the local aligner for massive biological data.}},
journal = {Bioinformatics (Oxford, England)},
year = {2014},
volume = {30},
number = {17},
pages = {i349--i355},
month = sep,
publisher = {Oxford University Press},
affiliation = {Department of Mathematics and Computer Science, Freie Universit{\"a}t Berlin, Takustr. 9, 14195 Berlin, Germany.},
doi = {10.1093/bioinformatics/btu439},
pmid = {25161219},
pmcid = {PMC4147892},
language = {English},
read = {Yes},
rating = {0},
date-added = {2014-09-08T12:33:47GMT},
date-modified = {2015-11-22T23:14:22GMT},
abstract = {MOTIVATION:Next-generation sequencing technologies produce unprecedented amounts of data, leading to completely new research fields. One of these is metagenomics, the study of large-size DNA samples containing a multitude of diverse organisms. A key problem in metagenomics is to functionally and taxonomically classify the sequenced DNA, to which end the well-known BLAST program is usually used. But BLAST has dramatic resource requirements at metagenomic scales of data, imposing a high financial or technical burden on the researcher. Multiple attempts have been made to overcome these limitations and present a viable alternative to BLAST.

RESULTS:In this work we present Lambda, our own alternative for BLAST in the context of sequence classification. In our tests, Lambda often outperforms the best tools at reproducing BLAST's results and is the fastest compared with the current state of the art at comparable levels of sensitivity.

AVAILABILITY AND IMPLEMENTATION:Lambda was implemented in the SeqAn open-source C++ library for sequence analysis and is publicly available for download at http://www.seqan.de/projects/lambda.

CONTACT:hannes.hauswedell@fu-berlin.de

SUPPLEMENTARY INFORMATION:Supplementary data are available at Bioinformatics online.},
url = {http://bioinformatics.oxfordjournals.org/content/30/17/i349.full},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Files/94/9488230A-A39B-4CC4-9E72-D226E28C7C90},
file = {{9488230A-A39B-4CC4-9E72-D226E28C7C90:/Users/reinert/Dropbox/Library.papers3/Files/94/9488230A-A39B-4CC4-9E72-D226E28C7C90:application/pdf;9488230A-A39B-4CC4-9E72-D226E28C7C90:/Users/reinert/Dropbox/Library.papers3/Files/94/9488230A-A39B-4CC4-9E72-D226E28C7C90:application/pdf}},
uri = {\url{papers3://publication/doi/10.1093/bioinformatics/btu439}}
}

@article{Rahn:2014bb,
author = {Rahn, R and Weese, David and Reinert, Knut},
title = {{Journaled string tree-a scalable data structure for analyzing thousands of similar genomes on your laptop.}},
journal = {Bioinformatics (Oxford, England)},
year = {2014},
pages = {btu438},
month = jul,
publisher = {Oxford University Press},
affiliation = {Department of Mathematics and Computer Science, Freie Universit{\"a}t Berlin, Takustr. 9, 14195 Berlin, Germany.},
doi = {10.1093/bioinformatics/btu438},
pmid = {25028723},
language = {English},
read = {Yes},
rating = {0},
date-added = {2014-08-14T06:36:08GMT},
date-modified = {2015-12-08T08:56:15GMT},
abstract = {MOTIVATION::Next-generation sequencing (NGS) has revolutionized biomedical research in the past decade and led to a continuous stream of developments in bioinformatics, addressing the need for fast and space-efficient solutions for analyzing NGS data. Often researchers need to analyze a set of genomic sequences that stem from closely related species or are indeed individuals of the same species. Hence, the analyzed sequences are similar. For analyses where local changes in the examined sequence induce only local changes in the results, it is obviously desirable to examine identical or similar regions not repeatedly.

RESULTS::In this work, we provide a datatype that exploits data parallelism inherent in a set of similar sequences by analyzing shared regions only once. In real-world experiments, we show that algorithms that otherwise would scan each reference sequentially can be speeded up by a factor of 115. Availability: The data structure and associated tools are publicly available at http://www.seqan.de/projects/jst and are part of SeqAn, the C++ template library for sequence analysis.

CONTACT::rene.rahn@fu-berlin.de.},
url = {http://bioinformatics.oxfordjournals.org/cgi/doi/10.1093/bioinformatics/btu438},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2014/Rahn/Bioinformatics%202014%20Rahn.pdf},
file = {{Bioinformatics 2014 Rahn.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2014/Rahn/Bioinformatics 2014 Rahn.pdf:application/pdf;Bioinformatics 2014 Rahn.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2014/Rahn/Bioinformatics 2014 Rahn.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1093/bioinformatics/btu438}}
}

@article{Trappe:2014bf,
author = {Trappe, Kathrin and Emde, A and Ehrlich, H C and Reinert, Knut},
title = {{Gustaf: Detecting and correctly classifying SVs in the NGS twilight zone.}},
journal = {Bioinformatics (Oxford, England)},
year = {2014},
pages = {btu431},
month = jul,
publisher = {Oxford University Press},
affiliation = {Department of Computer Science, Freie Universit{\"a}t Berlin, 14195 Berlin, Germany, Research Group Bioinformatics (NG4), Robert Koch Institute, 13353 Berlin, Germany and New York Genome Center, New York, NY 10013, USADepartment of Computer Science, Freie Universit{\"a}t Berlin, 14195 Berlin, Germany, Research Group Bioinformatics (NG4), Robert Koch Institute, 13353 Berlin, Germany and New York Genome Center, New York, NY 10013, USA.},
doi = {10.1093/bioinformatics/btu431},
pmid = {25028727},
language = {English},
read = {Yes},
rating = {4},
date-added = {2014-08-14T06:40:59GMT},
date-modified = {2015-12-08T08:56:37GMT},
abstract = {MOTIVATION:The landscape of structural variation (SV) including complex duplication and translocation patterns is far from resolved. SV detection tools usually exhibit low agreement, are often geared toward certain types or size ranges of variation and struggle to correctly classify the type and exact size of SVs.

RESULTS:We present Gustaf (Generic mUlti-SpliT Alignment Finder), a sound generic multi-split SV detection tool that detects and classifies deletions, inversions, dispersed duplications and translocations of $\ge$30 bp. Our approach is based on a generic multi-split alignment strategy that can identify SV breakpoints with base pair resolution. We show that Gustaf correctly identifies SVs, especially in the range from 30 to 100 bp, which we call the next-generation sequencing (NGS) twilight zone of SVs, as well as larger SVs >500 bp. Gustaf performs better than similar tools in our benchmark and is furthermore able to correctly identify size and location of dispersed duplications and translocations, which otherwise might be wrongly classified, for example, as large deletions. Availability and implementation: Project information, paper benchmark and source code are available via http://www.seqan.de/projects/gustaf/.

CONTACT:kathrin.trappe@fu-berlin.de.},
url = {http://bioinformatics.oxfordjournals.org/content/early/2014/07/29/bioinformatics.btu431.full},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2014/Trappe/Bioinformatics%202014%20Trappe.pdf},
file = {{Bioinformatics 2014 Trappe.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2014/Trappe/Bioinformatics 2014 Trappe.pdf:application/pdf;Bioinformatics 2014 Trappe.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2014/Trappe/Bioinformatics 2014 Trappe.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1093/bioinformatics/btu431}}
}

@article{Kehr:2014fo,
author = {Kehr, B. and Trappe, Kathrin and Holtgrewe, Manuel and Reinert, Knut},
title = {{Genome alignment with graph data structures: a comparison.}},
journal = {BMC Bioinformatics},
year = {2014},
volume = {15},
number = {1},
pages = {99},
month = apr,
publisher = {BioMed Central Ltd},
doi = {10.1186/1471-2105-15-99},
pmid = {24712884},
pmcid = {PMC4020321},
language = {English},
read = {Yes},
rating = {0},
date-added = {2014-04-14T07:02:55GMT},
date-modified = {2015-09-06T21:28:47GMT},
abstract = {BACKGROUND:Recent advances in rapid, low-cost sequencing have opened up the opportunity to study completegenome sequences. The computational approach of multiple genome alignment allows investigationof evolutionarily related genomes in an integrated fashion, providing a basis for downstream analysessuch as rearrangement studies and phylogenetic inference.Graphs have proven to be a powerful tool for coping with the complexity of genome-scale sequencealignments. The potential of graphs to intuitively represent all aspects of genome alignments led tothe development of graph-based approaches for genome alignment. These approaches construct agraph from a set of local alignments, and derive a genome alignment through identification andremoval of graph substructures that indicate errors in the alignment.

RESULTS:We compare the structures of commonly used graphs in terms of their abilities to represent alignmentinformation. We describe how the graphs can be transformed into each other, and identify andclassify graph substructures common to one or more graphs. Based on previous approaches, wecompile a list of modifications that remove these substructures.

CONCLUSION:We show that crucial pieces of alignment information, associated with inversions and duplications,are not visible in the structure of all graphs. If we neglect vertex or edge labels, the graphs differ intheir information content. Still, many ideas are shared among all graph-based approaches. Based onthese findings, we outline a conceptual framework for graph-based genome alignment that can assistin the development of future genome alignment tools.},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=24712884&retmode=ref&cmd=prlinks},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2014/Kehr/BMC%20Bioinformatics%202014%20Kehr.pdf},
file = {{BMC Bioinformatics 2014 Kehr.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2014/Kehr/BMC Bioinformatics 2014 Kehr.pdf:application/pdf;BMC Bioinformatics 2014 Kehr.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2014/Kehr/BMC Bioinformatics 2014 Kehr.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1186/1471-2105-15-99}}
}

@article{Venter2001Short,
author = {Hu, Jialu and Kehr, B. and Reinert, Knut},
title = {{NetCoffee: a fast and accurate global alignment approach to identify functionally conserved proteins in multiple networks.}},
journal = {Bioinformatics (Oxford, England)},
year = {2014},
volume = {30},
number = {4},
pages = {540--548},
month = feb,
publisher = {Oxford University Press},
affiliation = {Department of Mathematics and Computer Science, Freie Universit{\"a}t Berlin, Takustrasse 9, 14195 Berlin, Germany and Max Planck Institute for Molecular Genetics, Ihnestrasse 63-73, 14195 Berlin, Germany.},
doi = {10.1093/bioinformatics/btt715},
pmid = {24336806},
language = {English},
read = {Yes},
rating = {0},
date-added = {2013-09-04T14:04:12GMT},
date-modified = {2015-12-08T08:55:31GMT},
abstract = {MOTIVATION:Owing to recent advancements in high-throughput technologies, protein-protein interaction networks of more and more species become available in public databases. The question of how to identify functionally conserved proteins across species attracts a lot of attention in computational biology. Network alignments provide a systematic way to solve this problem. However, most existing alignment tools encounter limitations in tackling this problem. Therefore, the demand for faster and more efficient alignment tools is growing.

RESULTS:We present a fast and accurate algorithm, NetCoffee, which allows to find a global alignment of multiple protein-protein interaction networks. NetCoffee searches for a global alignment by maximizing a target function using simulated annealing on a set of weighted bipartite graphs that are constructed using a triplet approach similar to T-Coffee. To assess its performance, NetCoffee was applied to four real datasets. Our results suggest that NetCoffee remedies several limitations of previous algorithms, outperforms all existing alignment tools in terms of speed and nevertheless identifies biologically meaningful alignments.

AVAILABILITY:The source code and data are freely available for download under the GNU GPL v3 license at https://code.google.com/p/netcoffee/.},
url = {http://bioinformatics.oxfordjournals.org/cgi/doi/10.1093/bioinformatics/btt715},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Files/6B/6BF535A3-BBA5-4B92-B576-162BA7B97A43.pdf},
file = {{6BF535A3-BBA5-4B92-B576-162BA7B97A43.pdf:/Users/reinert/Dropbox/Library.papers3/Files/6B/6BF535A3-BBA5-4B92-B576-162BA7B97A43.pdf:application/pdf;6BF535A3-BBA5-4B92-B576-162BA7B97A43.pdf:/Users/reinert/Dropbox/Library.papers3/Files/6B/6BF535A3-BBA5-4B92-B576-162BA7B97A43.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1093/bioinformatics/btt715}}
}

@article{Andreotti:2013fw,
author = {Andreotti, Sandro and Reinert, Knut and Canzar, Stefan},
title = {{The duplication-loss small phylogeny problem: from cherries to trees.}},
journal = {Journal of Computational Biology},
year = {2013},
volume = {20},
number = {9},
pages = {643--659},
month = sep,
affiliation = {Department of Mathematics and Computer Science, Institute of Computer Science, Freie Universit{\"a}t Berlin, Berlin, Germany.},
doi = {10.1089/cmb.2013.0057},
pmid = {24000925},
pmcid = {PMC3761417},
language = {English},
read = {Yes},
rating = {0},
date-added = {2014-09-21T18:33:47GMT},
date-modified = {2015-09-02T15:44:06GMT},
abstract = {The reconstruction of the history of evolutionary genome-wide events among a set of related organisms is of great biological interest since it can help to reveal the genomic basis of phenotypes. The sequencing of whole genomes faciliates the study of gene families that vary in size through duplication and loss events, like transfer RNA. However, a high sequence similarity often does not allow one to distinguish between orthologs and paralogs. Previous methods have addressed this difficulty by taking into account flanking regions of members of a family independently. We go one step further by inferring the order of genes of (a set of) families for ancestral genomes by considering the order of these genes on sequenced genomes. We present a novel branch-and-cut algorithm to solve the two species small phylogeny problem in the evolutionary model of duplications and losses. On average, our implementation, DupLoCut, improves the running time of a recently proposed method in the experiments on six Vibrionaceae lineages by a factor of ∼200. Besides the mere improvement in running time, the efficiency of our approach allows us to extend our model from cherries of a species tree, that is, subtrees with two leaves, to the median of three species setting. Being able to determine the median of three species is of key importance to one of the most common approaches to ancestral reconstruction, and our experiments show that its repeated computation considerably reduces the number of duplications and losses along the tree both on simulated instances comprising 128 leaves and a set of Bacillus genomes. Furthermore, in our simulations we show that a reduction in cost goes hand in hand with an improvement of the predicted ancestral genomes. Finally, we prove that the small phylogeny problem in the duplication-loss model is NP-complete already for two species.},
url = {http://online.liebertpub.com/doi/abs/10.1089/cmb.2013.0057},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Files/86/867DE7BC-3F9A-46E8-B5AF-07445C8C1B96.pdf},
file = {{867DE7BC-3F9A-46E8-B5AF-07445C8C1B96.pdf:/Users/reinert/Dropbox/Library.papers3/Files/86/867DE7BC-3F9A-46E8-B5AF-07445C8C1B96.pdf:application/pdf;867DE7BC-3F9A-46E8-B5AF-07445C8C1B96.pdf:/Users/reinert/Dropbox/Library.papers3/Files/86/867DE7BC-3F9A-46E8-B5AF-07445C8C1B96.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1089/cmb.2013.0057}}
}

@inproceedings{Siragusa:2013dx,
author = {Siragusa, Enrico and Weese, David and Reinert, Knut},
title = {{Scalable string similarity search/join with approximate seeds and multiple backtracking}},
booktitle = {EDBT '13: Proceedings of the Joint EDBT/ICDT 2013 Workshops},
year = {2013},
pages = {370--374},
publisher = {~ACM  Request Permissions},
address = {New York, New York, USA},
month = mar,
doi = {10.1145/2457317.2457386},
isbn = {9781450315999},
read = {Yes},
rating = {0},
date-added = {2014-04-05T07:22:02GMT},
date-modified = {2015-07-12T09:51:09GMT},
abstract = {We present in this paper scalable algorithms for optimal string similarity search and join. Our methods are variations of those applied in Masai [15], our recently published tool for mapping high-throughput DNA sequencing data with unpreceded},
url = {http://dl.acm.org/citation.cfm?doid=2457317.2457386},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Files/EC/EC14F5DB-5321-44F8-BD50-ACC9917030B7.pdf},
file = {{EC14F5DB-5321-44F8-BD50-ACC9917030B7.pdf:/Users/reinert/Dropbox/Library.papers3/Files/EC/EC14F5DB-5321-44F8-BD50-ACC9917030B7.pdf:application/pdf;EC14F5DB-5321-44F8-BD50-ACC9917030B7.pdf:/Users/reinert/Dropbox/Library.papers3/Files/EC/EC14F5DB-5321-44F8-BD50-ACC9917030B7.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1145/2457317.2457386}}
}

@article{Nahnsen:2013uu,
author = {Nahnsen, Sven and Bielow, Chris and Reinert, Knut and Kohlbacher, Oliver},
title = {{Tools for label-free peptide quantification.}},
journal = {Molecular {\&}amp; Cellular Proteomics},
year = {2013},
volume = {12},
number = {3},
pages = {549--556},
month = mar,
publisher = {American Society for Biochemistry and Molecular Biology},
affiliation = {Center for Bioinformatics, Quantitative Biology Center and Department of Computer Science, University of T{\"u}bingen, T{\"u}bingen, Germany.},
doi = {10.1074/mcp.R112.025163},
pmid = {23250051},
pmcid = {PMC3591650},
language = {English},
rating = {0},
date-added = {2015-09-08T22:49:42GMT},
date-modified = {2015-12-08T10:10:02GMT},
abstract = {The increasing scale and complexity of quantitative proteomics studies complicate subsequent analysis of the acquired data. Untargeted label-free quantification, based either on feature intensities or on spectral counting, is a method that scales particularly well with respect to the number of samples. It is thus an excellent alternative to labeling techniques. In order to profit from this scalability, however, data analysis has to cope with large amounts of data, process them automatically, and do a thorough statistical analysis in order to achieve reliable results. We review the state of the art with respect to computational tools for label-free quantification in untargeted proteomics. The two fundamental approaches are feature-based quantification, relying on the summed-up mass spectrometric intensity of peptides, and spectral counting, which relies on the number of MS/MS spectra acquired for a certain protein. We review the current algorithmic approaches underlying some widely used software packages and briefly discuss the statistical strategies for analyzing the data.},
url = {http://www.mcponline.org/content/12/3/549.full},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Files/8D/8D965654-C01B-44C7-9139-DFB9A57D3CC7},
file = {{8D965654-C01B-44C7-9139-DFB9A57D3CC7:/Users/reinert/Dropbox/Library.papers3/Files/8D/8D965654-C01B-44C7-9139-DFB9A57D3CC7:application/pdf}},
uri = {\url{papers3://publication/doi/10.1074/mcp.R112.025163}}
}

@article{Neu:2013bt,
author = {Neu, Volker and Bielow, Chris and Schneider, Peter and Reinert, Knut and Stuppner, Hermann and Huber, Christian G},
title = {{Investigation of reaction mechanisms of drug degradation in the solid state: a kinetic study implementing ultrahigh-performance liquid chromatography and high-resolution mass spectrometry for thermally stressed thyroxine.}},
journal = {Analytical chemistry},
year = {2013},
volume = {85},
number = {4},
pages = {2385--2390},
month = feb,
affiliation = {Department of Molecular Biology, Division of Chemistry and Bioanalytics, University of Salzburg, Hellbrunner Strasse 34, 5020 Salzburg, Austria.},
doi = {10.1021/ac303404e},
pmid = {23311729},
language = {English},
rating = {0},
date-added = {2015-09-08T22:49:39GMT},
date-modified = {2015-11-26T15:38:49GMT},
abstract = {A reaction scheme was derived for the thermal degradation of thyroxine in the solid state, using data obtained from ultrahigh-performance liquid chromatography and high-resolution mass spectrometry (UHPLC-HRMS). To study the reaction mechanism and kinetics of the thermal degradation of the pharmaceutical in the solid state, a workflow was developed by generating compound-specific, time-dependent degradation or formation curves of at least 13 different degradation products. Such curves allowed one to distinguish between first- and second-generation degradation products, as well as impurities resulting from chemical synthesis. The structures of the degradation products were derived from accurate molecular masses and multistage mass spectrometry. Deiodination and oxidative side chain degradation were found to be the major degradation reactions, resulting in the formation of deiodinated thyroxines, as well as acetic acid, benzoic acid, formaldehyde, acetamide, hydroxyacetic acid, oxoacetic acid, hydroxyacetamide, or oxoacetamide derivatives of thyroxine or deiodinated thyroxine. Upon additional structural verification of mass spectrometric data using nuclear magnetic resonance spectroscopy, this comprehensive body of data sheds light on an elaborate, radical-driven reaction scheme, explaining the presence or formation of impurities in thermally stressed thyroxine.},
url = {http://pubs.acs.org/doi/abs/10.1021/ac303404e},
uri = {\url{papers3://publication/doi/10.1021/ac303404e}}
}

@article{Siragusa:2013ir,
author = {Siragusa, Enrico and Weese, David and Reinert, Knut},
title = {{Fast and accurate read mapping with approximate seeds and multiple backtracking.}},
journal = {Nucleic Acids Research},
year = {2013},
volume = {41},
number = {7},
pages = {e78--e78},
month = jan,
publisher = {Oxford University Press},
affiliation = {Department of Mathematics and Computer Science, Freie Universit{\"a}t Berlin, Takustr. 9, 14195 Berlin, Germany and Max Planck Institute for Molecular Genetics, Ihnestr. 63-73, 14195 Berlin, Germany.},
keywords = {read mapping},
doi = {10.1093/nar/gkt005},
pmid = {23358824},
pmcid = {PMC3627565},
language = {English},
read = {Yes},
rating = {5},
date-added = {2013-02-01T08:24:19GMT},
date-modified = {2015-12-11T12:51:34GMT},
abstract = {We present Masai, a read mapper representing the state-of-the-art in terms of speed and accuracy. Our tool is an order of magnitude faster than RazerS 3 and mrFAST, 2-4 times faster and more accurate than Bowtie 2 and BWA. The novelties of our read mapper are filtration with approximate seeds and a method for multiple backtracking. Approximate seeds, compared with exact seeds, increase filtration specificity while preserving sensitivity. Multiple backtracking amortizes the cost of searching a large set of seeds by taking advantage of the repetitiveness of next-generation sequencing data. Combined together, these two methods significantly speed up approximate search on genomic data sets. Masai is implemented in C++ using the SeqAn library. The source code is distributed under the BSD license and binaries for Linux, Mac OS X and Windows can be freely downloaded from http://www.seqan.de/projects/masai.},
url = {http://nar.oxfordjournals.org/content/41/7/e78.full},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2013/Siragusa/Nucleic%20Acids%20Res%202013%20Siragusa.pdf},
file = {{Nucleic Acids Res 2013 Siragusa.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2013/Siragusa/Nucleic Acids Res 2013 Siragusa.pdf:application/pdf;Nucleic Acids Res 2013 Siragusa.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2013/Siragusa/Nucleic Acids Res 2013 Siragusa.pdf:application/pdf}},
uri = {\url{papers3://publication/livfe/id/115946}}
}

@article{zerck_13_optimal,
author = {Zerck, Alexandra and Nordhoff, E and Lehrach, H and Reinert, Knut},
title = {{Optimal precursor ion selection for LC-MALDI MS/MS}},
journal = {BMC Bioinformatics},
year = {2013},
volume = {14},
number = {1},
pages = {56},
publisher = {BioMed Central Ltd},
pmid = {23418672},
pmcid = {PMC3651328},
read = {Yes},
rating = {0},
date-added = {2013-08-22T13:50:11GMT},
date-modified = {2015-09-02T15:45:04GMT},
abstract = {Background Liquid chromatography mass spectrometry (LC-MS) maps in shotgun proteomics are often too complex to select every detected peptide signal for fragmentation by tandem mass spectrometry (MS/MS). Standard methods for precursor ion selection , ... 
},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=23418672&retmode=ref&cmd=prlinks},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2013/Zerck/BMC%20Bioinformatics%202013%20Zerck.pdf},
file = {{BMC Bioinformatics 2013 Zerck.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2013/Zerck/BMC Bioinformatics 2013 Zerck.pdf:application/pdf;BMC Bioinformatics 2013 Zerck.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2013/Zerck/BMC Bioinformatics 2013 Zerck.pdf:application/pdf}},
uri = {\url{papers3://publication/uuid/5AD57DA5-EF19-4AD1-9C6E-C35EBB99B782}}
}

@article{Weese:2012byb,
author = {Weese, David and Holtgrewe, Manuel and Reinert, Knut},
title = {{RazerS 3: faster, fully sensitive read mapping.}},
journal = {Bioinformatics (Oxford, England)},
year = {2012},
volume = {28},
number = {20},
pages = {2592--2599},
month = oct,
publisher = {Oxford University Press},
affiliation = {Department of Mathematics and Computer Science, Freie Universit{\"a}t Berlin, Berlin, Germany. david.weese@fu-berlin.de},
doi = {10.1093/bioinformatics/bts505},
pmid = {22923295},
language = {English},
read = {Yes},
rating = {0},
date-added = {2014-06-18T11:28:14GMT},
date-modified = {2015-11-23T14:10:44GMT},
abstract = {MOTIVATION:During the past years, next-generation sequencing has become a key technology for many applications in the biomedical sciences. Throughput continues to increase and new protocols provide longer reads than currently available. In almost all applications, read mapping is a first step. Hence, it is crucial to have algorithms and implementations that perform fast, with high sensitivity, and are able to deal with long reads and a large absolute number of insertions and deletions.

RESULTS:RazerS is a read mapping program with adjustable sensitivity based on counting q-grams. In this work, we propose the successor RazerS 3, which now supports shared-memory parallelism, an additional seed-based filter with adjustable sensitivity, a much faster, banded version of the Myers' bit-vector algorithm for verification, memory-saving measures and support for the SAM output format. This leads to a much improved performance for mapping reads, in particular, long reads with many errors. We extensively compare RazerS 3 with other popular read mappers and show that its results are often superior to them in terms of sensitivity while exhibiting practical and often competitive run times. In addition, RazerS 3 works without a pre-computed index.

AVAILABILITY AND IMPLEMENTATION:Source code and binaries are freely available for download at http://www.seqan.de/projects/razers. RazerS 3 is implemented in C++ and OpenMP under a GPL license using the SeqAn library and supports Linux, Mac OS X and Windows.},
url = {http://bioinformatics.oxfordjournals.org/cgi/doi/10.1093/bioinformatics/bts505},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2012/Weese/Bioinformatics%202012%20Weese-1.pdf},
file = {{Bioinformatics 2012 Weese-1.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2012/Weese/Bioinformatics 2012 Weese-1.pdf:application/pdf;Bioinformatics 2012 Weese-1.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2012/Weese/Bioinformatics 2012 Weese-1.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1093/bioinformatics/bts505}}
}

@article{Kehr:2012ve,
author = {Kehr, B. and Reinert, Knut and Darling, Aaron E},
title = {{Hidden breakpoints in genome alignments}},
journal = {arXiv.org},
year = {2012},
eprint = {1207.6964v1},
eprinttype = {arxiv},
eprintclass = {q-bio.GN},
month = jul,
annote = {13 pages, 4 figures},
read = {Yes},
rating = {0},
date-added = {2015-04-13T09:48:53GMT},
date-modified = {2015-12-08T08:55:54GMT},
abstract = {During the course of evolution, an organism's genome can undergo changes that affect the large-scale structure of the genome. These changes include gene gain, loss, duplication, chromosome fusion, fission, and rearrangement. When gene gain and loss occurs in addition to other types of rearrangement, breakpoints of rearrangement can exist that are only detectable by comparison of three or more genomes. An arbitrarily large number of these "hidden" breakpoints can exist among genomes that exhibit no rearrangements in pairwise comparisons. We present an extension of the multichromosomal breakpoint median problem to genomes that have undergone gene gain and loss. We then demonstrate that the median distance among three genomes can be used to calculate a lower bound on the number of hidden breakpoints present. We provide an implementation of this calculation including the median distance, along with some practical improvements on the time complexity of the underlying algorithm. We apply our approach to measure the abundance of hidden breakpoints in simulated data sets under a wide range of evolutionary scenarios. We demonstrate that in simulations the hidden breakpoint counts depend strongly on relative rates of inversion and gene gain/loss. Finally we apply current multiple genome aligners to the simulated genomes, and show that all aligners introduce a high degree of error in hidden breakpoint counts, and that this error grows with evolutionary distance in the simulation. Our results suggest that hidden breakpoint error may be pervasive in genome alignments.

Published in: WABI 2012, LNBI 7534:391-403 (2012)},
url = {http://arxiv.org/abs/1207.6964v1},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Files/6F/6FE28553-AE91-4E7B-A904-5F5AB180EF85.pdf},
file = {{6FE28553-AE91-4E7B-A904-5F5AB180EF85.pdf:/Users/reinert/Dropbox/Library.papers3/Files/6F/6FE28553-AE91-4E7B-A904-5F5AB180EF85.pdf:application/pdf}},
uri = {\url{papers3://publication/uuid/B77C491A-311D-44AE-83F8-334414CA85E1}}
}

@article{Aiche:2012gt,
author = {Aiche, Stephan and Reinert, Knut and Sch{\"u}tte, Christof and Hildebrand, Diana and Schl{\"u}ter, Hartmut and Conrad, Tim},
title = {{Inferring Proteolytic Processes from Mass Spectrometry Time Series Data Using Degradation Graphs}},
journal = {PLoS ONE},
year = {2012},
volume = {7},
number = {7},
pages = {e40656},
month = jul,
doi = {10.1371/journal.pone.0040656.t003},
language = {English},
read = {Yes},
rating = {0},
date-added = {2012-07-23T12:17:18GMT},
date-modified = {2015-11-27T08:48:03GMT},
url = {http://dx.plos.org/10.1371/journal.pone.0040656.t003},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2012/Aiche/PLoS%20ONE%202012%20Aiche.pdf},
file = {{PLoS ONE 2012 Aiche.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2012/Aiche/PLoS ONE 2012 Aiche.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1371/journal.pone.0040656.t003}}
}

@article{Junker:2012dt,
author = {Junker, Johannes and Bielow, Chris and Bertsch, A and Sturm, Marc and Reinert, Knut and Kohlbacher, Oliver},
title = {{TOPPAS: a graphical workflow editor for the analysis of high-throughput proteomics data.}},
journal = {Journal of Proteome Research},
year = {2012},
volume = {11},
number = {7},
pages = {3914--3920},
month = jul,
affiliation = {Applied Bioinformatics, Center for Bioinformatics and Quantitative Biology Center, University of T{\"u}bingen, T{\"u}bingen, Germany. johannes.junker@uni-tuebingen.de},
doi = {10.1021/pr300187f},
pmid = {22583024},
language = {English},
rating = {0},
date-added = {2015-09-08T22:49:53GMT},
date-modified = {2015-11-26T15:38:49GMT},
abstract = {Mass spectrometry coupled to high-performance liquid chromatography (HPLC-MS) is evolving more quickly than ever. A wide range of different instrument types and experimental setups are commonly used. Modern instruments acquire huge amounts of data, thus requiring tools for an efficient and automated data analysis. Most existing software for analyzing HPLC-MS data is monolithic and tailored toward a specific application. A more flexible alternative consists of pipeline-based tool kits allowing the construction of custom analysis workflows from small building blocks, e.g., the Trans Proteomics Pipeline (TPP) or The OpenMS Proteomics Pipeline (TOPP). One drawback, however, is the hurdle of setting up complex workflows using command line tools. We present TOPPAS, The OpenMS Proteomics Pipeline ASsistant, a graphical user interface (GUI) for rapid composition of HPLC-MS analysis workflows. Workflow construction reduces to simple drag-and-drop of analysis tools and adding connections in between. Integration of external tools into these workflows is possible as well. Once workflows have been developed, they can be deployed in other workflow management systems or batch processing systems in a fully automated fashion. The implementation is portable and has been tested under Windows, Mac OS X, and Linux. TOPPAS is open-source software and available free of charge at http://www.OpenMS.de/TOPPAS .},
url = {http://pubs.acs.org/doi/abs/10.1021/pr300187f},
uri = {\url{papers3://publication/doi/10.1021/pr300187f}}
}

@article{Emde:2012ui,
author = {Emde, A and Schulz, Marcel H and Weese, David and Sun, Ruping and Vingron, Martin and Kalscheuer, Vera M and Haas, Stefan A and Reinert, Knut},
title = {{Detecting genomic indel variants with exact breakpoints in single- and paired-end sequencing data using SplazerS}},
journal = {Bioinformatics (Oxford, England)},
year = {2012},
volume = {28},
number = {5},
pages = {619--627},
month = mar,
publisher = {Oxford University Press},
affiliation = {Department of Computer Science, Freie Universit{\"a}t Berlin, Takustrasse 9, Max-Planck-Institute for Molecular Genetics, Berlin, Germany. emde@inf.fu-berlin.de},
doi = {10.1093/bioinformatics/bts019},
pmid = {22238266},
language = {English},
read = {Yes},
rating = {5},
date-added = {2012-01-24T21:49:19GMT},
date-modified = {2015-11-24T21:03:56GMT},
abstract = {MOTIVATION:The reliable detection of genomic variation in resequencing data is still a major challenge, especially for variants larger than a few base pairs. Sequencing reads crossing boundaries of structural variation carry the potential for their identification, but are difficult to map.

RESULTS:Here we present a method for 'split' read mapping, where prefix and suffix match of a read may be interrupted by a longer gap in the read-to-reference alignment. We use this method to accurately detect medium-sized insertions and long deletions with precise breakpoints in genomic resequencing data. Compared with alternative split mapping methods, SplazerS significantly improves sensitivity for detecting large indel events, especially in variant-rich regions. Our method is robust in the presence of sequencing errors as well as alignment errors due to genomic mutations/divergence, and can be used on reads of variable lengths. Our analysis shows that SplazerS is a versatile tool applicable to unanchored or single-end as well as anchored paired-end reads. In addition, application of SplazerS to targeted resequencing data led to the interesting discovery of a complete, possibly functional gene retrocopy variant.

AVAILABILITY:SplazerS is available from http://www.seqan.de/projects/ splazers.

SUPPLEMENTARY INFORMATION:Supplementary data are available at Bioinformatics online.},
url = {http://bioinformatics.oxfordjournals.org/content/28/5/619.full},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2012/Emde/Bioinformatics%202012%20Emde.pdf},
file = {{Bioinformatics 2012 Emde.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2012/Emde/Bioinformatics 2012 Emde.pdf:application/pdf;Bioinformatics 2012 Emde.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2012/Emde/Bioinformatics 2012 Emde.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1093/bioinformatics/bts019}}
}

@article{Bauer:2012bf,
author = {Bauer, Chris and Kleinjung, Frank and Ruthishauser, Dorothea and Panse, Christian and Chadt, Alexandra and Dreja, Tanja and Al-Hasani, Hadi and Reinert, Knut and Schlapbach, Ralph and Schuchhardt, Johannes},
title = {{PPINGUIN: Peptide Profiling Guided Identification of Proteins Improves Quantitation of iTRAQ Ratios.}},
journal = {BMC Bioinformatics},
year = {2012},
volume = {13},
number = {1},
pages = {34},
month = feb,
doi = {10.1186/1471-2105-13-34},
pmid = {22340093},
pmcid = {PMC3368728},
language = {English},
rating = {0},
date-added = {2012-04-24T07:43:53GMT},
date-modified = {2015-11-06T12:10:17GMT},
abstract = {ABSTRACT: BACKGROUND: Recent development of novel technologies paved the way for quantitative proteomics. One of the most important among them is iTRAQ, employing isobaric tags for relative or absolute quantitation. Despite large progress in technology development, still many challenges remain for derivation and interpretation of quantitative results. One of these challenges is the consistent assignment of peptides to proteins. RESULTS: We have developed Peptide Profiling Guided Identification of Proteins (PPINGUIN), a statistical analysis workflow for iTRAQ data addressing the problem of ambiguous peptide quantitations. Motivated by the assumption that peptides uniquely derived from the same protein are correlated, our method employs clustering as a very early step in data processing prior to protein inference. Our method increases experimental reproducibility and decreases variability of quantitations of peptides assigned to the same protein. Giving further support to our method, application to a type 2 diabetes dataset identifies a list of protein candidates that is in very good agreement with previously performed transcriptomics meta analysis. Making use of quantitative properties of signal patterns identified, PPINGUIN can reveal new isoform candidates. CONCLUSIONS: Regarding the increasing importance of quantitative proteomics we think that this method will be useful in practical applications like model fitting or functional enrichment analysis. We recommend to use this method if quantitation is a major objective of research.},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=22340093&retmode=ref&cmd=prlinks},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2012/Bauer/BMC%20Bioinformatics%202012%20Bauer.pdf},
file = {{BMC Bioinformatics 2012 Bauer.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2012/Bauer/BMC Bioinformatics 2012 Bauer.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1186/1471-2105-13-34}}
}

@article{Aiche:2012ip,
author = {Aiche, Stephan and Reinert, Knut and Sch{\"u}tte, Christof and Hildebrand, Diana and Schl{\"u}ter, Hartmut and Conrad, Tim},
title = {{Inferring proteolytic processes from mass spectrometry time series data using degradation graphs.}},
journal = {PLoS ONE},
year = {2012},
volume = {7},
number = {7},
pages = {e40656},
affiliation = {Department of Mathematics and Computer Science, Freie Universit{\"a}t Berlin, Berlin, Germany. stephan.aiche@fu-berlin.de},
doi = {10.1371/journal.pone.0040656},
pmid = {22815782},
pmcid = {PMC3398944},
language = {English},
rating = {0},
date-added = {2015-09-08T22:49:56GMT},
date-modified = {2015-11-26T15:38:49GMT},
abstract = {BACKGROUND:Proteases play an essential part in a variety of biological processes. Besides their importance under healthy conditions they are also known to have a crucial role in complex diseases like cancer. In recent years, it has been shown that not only the fragments produced by proteases but also their dynamics, especially ex vivo, can serve as biomarkers. But so far, only a few approaches were taken to explicitly model the dynamics of proteolysis in the context of mass spectrometry.

RESULTS:We introduce a new concept to model proteolytic processes, the degradation graph. The degradation graph is an extension of the cleavage graph, a data structure to reconstruct and visualize the proteolytic process. In contrast to previous approaches we extended the model to incorporate endoproteolytic processes and present a method to construct a degradation graph from mass spectrometry time series data. Based on a degradation graph and the intensities extracted from the mass spectra it is possible to estimate reaction rates of the underlying processes. We further suggest a score to rate different degradation graphs in their ability to explain the observed data. This score is used in an iterative heuristic to improve the structure of the initially constructed degradation graph.

CONCLUSION:We show that the proposed method is able to recover all degraded and generated peptides, the underlying reactions, and the reaction rates of proteolytic processes based on mass spectrometry time series data. We use simulated and real data to demonstrate that a given process can be reconstructed even in the presence of extensive noise, isobaric signals and false identifications. While the model is currently only validated on peptide data it is also applicable to proteins, as long as the necessary time series data can be produced.},
url = {http://dx.plos.org/10.1371/journal.pone.0040656},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Files/CA/CA2B96B7-6A94-4DE1-B0BF-7FB9111FF6E5.pdf},
file = {{CA2B96B7-6A94-4DE1-B0BF-7FB9111FF6E5.pdf:/Users/reinert/Dropbox/Library.papers3/Files/CA/CA2B96B7-6A94-4DE1-B0BF-7FB9111FF6E5.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1371/journal.pone.0040656}}
}

@article{Bauer:2011jj,
author = {Bauer, Chris and Kleinjung, Frank and Smith, Celia J and Towers, Mark W and Tiss, Ali and Chadt, Alexandra and Dreja, Tanja and Beule, Dieter and Al-Hasani, Hadi and Reinert, Knut and Schuchhardt, Johannes and Cramer, Rainer},
title = {{Biomarker Discovery and Redundancy Reduction towards Classification using a Multi-factorial MALDI-TOF MS T2DM Mouse Model Dataset.}},
journal = {BMC Bioinformatics},
year = {2011},
volume = {12},
number = {1},
pages = {140},
month = may,
doi = {10.1186/1471-2105-12-140},
pmid = {21554713},
pmcid = {PMC3116487},
language = {English},
rating = {0},
date-added = {2011-06-17T19:45:33GMT},
date-modified = {2015-11-06T12:10:16GMT},
abstract = {ABSTRACT: BACKGROUND: Diabetes like many diseases and biological processes is not mono-causal. On the one hand multi-factorial studies with complex experimental design are required for its comprehensive analysis. On the other hand, the data from these studies often include a substantial amount of redundancy such as proteins that are typically represented by a multitude of peptides. Coping simultaneously with both complexities (experimental and technological) makes data analysis a challenge for Bioinformatics. RESULTS: We present a comprehensive work-flow tailored for analyzing complex data including data from multi-factorial studies. The developed approach aims at revealing effects caused by a distinct combination of experimental factors, in our case genotype and diet. Applying the developed work-flow to the analysis of an established polygenic mouse model for diet-induced type 2 diabetes, we found peptides with significant fold changes exclusively for the combination of a particular strain and diet. Exploitation of redundancy enables the visualization of peptide correlation and provides a natural way of feature selection for classification and prediction. Classification based on the features selected using our approach performs similar to classifications based on more complex feature selection methods. CONCLUSIONS: The combination of ANOVA and redundancy exploitation allows for identification of biomarker candidates in multi-dimensional MALDI-TOF MS profiling studies with complex experimental design. With respect to feature selection our method provides a fast and intuitive alternative to global optimization strategies with comparable performance. The method is implemented in R and the scripts are available by contacting the corresponding author.},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=21554713&retmode=ref&cmd=prlinks},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2011/Bauer/BMC%20Bioinformatics%202011%20Bauer.pdf},
file = {{BMC Bioinformatics 2011 Bauer.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2011/Bauer/BMC Bioinformatics 2011 Bauer.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1186/1471-2105-12-140}}
}

@article{Bielow:2011ke,
author = {Bielow, Chris and Aiche, Stephan and Andreotti, Sandro and Reinert, Knut},
title = {{MSSimulator: Simulation of Mass Spectrometry Data}},
journal = {Journal of Proteome Research},
year = {2011},
pages = {110428145212024},
month = apr,
doi = {10.1021/pr200155f},
pmid = {21526843},
language = {English},
read = {Yes},
rating = {0},
date-added = {2011-04-29T16:28:51GMT},
date-modified = {2015-11-06T12:10:16GMT},
url = {http://pubs.acs.org/doi/abs/10.1021/pr200155f},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2011/Bielow/J%20Proteome%20Res%202011%20Bielow.pdf},
file = {{J Proteome Res 2011 Bielow.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2011/Bielow/J Proteome Res 2011 Bielow.pdf:application/pdf;J Proteome Res 2011 Bielow.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2011/Bielow/J Proteome Res 2011 Bielow.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1021/pr200155f}}
}

@article{Andreotti:2011bua,
author = {Andreotti, Sandro and Klau, Gunnar W and Reinert, Knut},
title = {{Antilope - A Lagrangian Relaxation Approach to the de novo Peptide Sequencing Problem}},
journal = {arXiv.org},
year = {2011},
eprint = {1102.4016v1},
eprinttype = {arxiv},
eprintclass = {cs.DS},
number = {2},
pages = {385--394},
month = feb,
affiliation = {Freie Universit{\"a}t Berlin, Germany and the International Max Planck Research School for Computational Biology and Scientific Computing, Berlin.},
doi = {10.1109/TCBB.2011.59},
pmid = {21464512},
language = {English},
read = {Yes},
rating = {0},
date-added = {2015-09-08T22:49:58GMT},
date-modified = {2015-12-06T19:15:18GMT},
abstract = {Peptide sequencing from mass spectrometry data is a key step in proteome research. Especially de novo sequencing, the identification of a peptide from its spectrum alone, is still a challenge even for state-of-the-art algorithmic approaches. In this paper we present Antilope, a new fast and flexible approach based on mathematical programming. It builds on the spectrum graph model and works with a variety of scoring schemes. Antilope combines Lagrangian relaxation for solving an integer linear programming formulation with an adaptation of Yen's k shortest paths algorithm. It shows a significant improvement in running time compared to mixed integer optimization and performs at the same speed like other state-of-the-art tools. We also implemented a generic probabilistic scoring scheme that can be trained automatically for a dataset of annotated spectra and is independent of the mass spectrometer type. Evaluations on benchmark data show that Antilope is competitive to the popular state-of-the-art programs PepNovo and NovoHMM both in terms of run time and accuracy. Furthermore, it offers increased flexibility in the number of considered ion types. Antilope will be freely available as part of the open source proteomics library OpenMS.},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5740842},
uri = {\url{papers3://publication/doi/10.1109/TCBB.2011.59}}
}

@book{Bielow:2011dka,
author = {Bielow, Chris and Gr{\"o}pl, Clemens and Kohlbacher, Oliver and Reinert, Knut},
editor = {Mayer, Bernd},
title = {{Methods in Molecular Biology}},
publisher = {Humana Press},
year = {2011},
volume = {719},
series = {Methods in Molecular Biology1064-37451940-6029},
address = {Totowa, NJ},
month = jan,
affiliation = {AG Algorithmische Bioinformatik, Institut f{\"u}r Informatik, Freie Universit{\"a}t Berlin, Berlin, Germany, bielow@mi.fu-berlin.de.},
doi = {10.1007/978-1-61779-027-0_15},
isbn = {978-1-61779-026-3},
rating = {0},
date-added = {2011-04-05T21:29:34GMT},
date-modified = {2015-11-06T12:10:05GMT},
abstract = {Mass spectrometry is today a key analytical technique to elucidate the amount and content of proteins expressed in a certain cellular context. The degree of automation in proteomics has yet to reach that of genomic techniques, but even current technologies make a manual inspection of the data infeasible. This article addresses the key algorithmic problems bioinformaticians face when handling modern proteomic samples and shows common solutions to them. We provide examples on how algorithms can be combined to build relatively complex analysis pipelines, point out certain pitfalls and aspects worth considering and give a list of current state-of-the-art tools.},
url = {http://www.springerlink.com/index/10.1007/978-1-61779-027-0_15},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Books/2011/Bielow/Methods%20Mol%20Biol%202011%20Bielow.pdf},
file = {{Methods Mol Biol 2011 Bielow.pdf:/Users/reinert/Dropbox/Library.papers3/Books/2011/Bielow/Methods Mol Biol 2011 Bielow.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1007/978-1-61779-027-0_15}}
}

@article{Bertsch:2011kh,
author = {Bertsch, A and Gr{\"o}pl, Clemens and Reinert, Knut and Kohlbacher, Oliver},
title = {{OpenMS and TOPP: open source software for LC-MS data analysis.}},
journal = {Methods in molecular biology (Clifton, NJ)},
year = {2011},
volume = {696},
pages = {353--367},
affiliation = {Division for Simulation of Biological Systems, WSI/ZBIT, Eberhard-Karls-Universit{\"a}t T{\"u}bingen, T{\"u}bingen, Germany.},
doi = {10.1007/978-1-60761-987-1_23},
pmid = {21063960},
language = {English},
rating = {0},
date-added = {2011-04-01T22:48:47GMT},
date-modified = {2015-11-06T12:10:15GMT},
abstract = {Proteomics experiments based on state-of-the-art mass spectrometry produce vast amounts of data, which cannot be analyzed manually. Hence, software is needed which is able to analyze the data in an automated fashion. The need for robust and reusable software tools triggered the development of libraries implementing different algorithms for the various analysis steps. OpenMS is such a software library and provides a wealth of data structures and algorithms for the analysis of mass spectrometric data. For users unfamiliar with programming, TOPP ("The OpenMS Proteomics Pipeline") offers a wide range of already implemented tools sharing the same interface and designed for a specific analysis task each. TOPP thus makes the sophisticated algorithms of OpenMS accessible to nonprogrammers. The individual TOPP tools can be strung together into pipelines for analyzing mass spectrometry-based experiments starting from the raw output of the mass spectrometer. These analysis pipelines can be constructed using a graphical editor. Even complex analytical workflows can thus be analyzed with ease.},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=21063960&retmode=ref&cmd=prlinks},
uri = {\url{papers3://publication/doi/10.1007/978-1-60761-987-1_23}}
}

@article{Kehr:2011vo,
author = {Kehr, B. and Weese, David and Reinert, Knut},
title = {{STELLAR: fast and exact local alignments}},
journal = {BMC Bioinformatics},
year = {2011},
volume = {12},
number = {Suppl 9},
pages = {S15},
publisher = {BioMed Central Ltd},
pmid = {22151882},
pmcid = {PMC3283304},
read = {Yes},
rating = {0},
date-added = {2011-12-01T08:31:26GMT},
date-modified = {2015-11-06T12:10:17GMT},
url = {http://www.biomedcentral.com/qc/1471-2105/12/S9/S15/},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2011/Kehr/BMC%20Bioinformatics%202011%20Kehr.pdf},
file = {{BMC Bioinformatics 2011 Kehr.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2011/Kehr/BMC Bioinformatics 2011 Kehr.pdf:application/pdf}},
uri = {\url{papers3://publication/uuid/630CE1B9-6448-4291-920F-CE4C53F31751}}
}

@article{Bielow:2011dk,
author = {Bielow, Chris and Gr{\"o}pl, Clemens and Kohlbacher, Oliver and Reinert, Knut},
title = {{Bioinformatics for qualitative and quantitative proteomics.}},
journal = {Methods in molecular biology (Clifton, NJ)},
year = {2011},
volume = {719},
pages = {331--349},
annote = {ert},
affiliation = {AG Algorithmische Bioinformatik, Institut f{\"u}r Informatik, Freie Universit{\"a}t Berlin, Berlin, Germany, bielow@mi.fu-berlin.de.},
doi = {10.1007/978-1-61779-027-0_15},
pmid = {21370091},
language = {English},
rating = {0},
date-added = {2011-04-01T22:48:50GMT},
date-modified = {2015-11-06T12:10:15GMT},
abstract = {Mass spectrometry is today a key analytical technique to elucidate the amount and content of proteins expressed in a certain cellular context. The degree of automation in proteomics has yet to reach that of genomic techniques, but even current technologies make a manual inspection of the data infeasible. This article addresses the key algorithmic problems bioinformaticians face when handling modern proteomic samples and shows common solutions to them. We provide examples on how algorithms can be combined to build relatively complex analysis pipelines, point out certain pitfalls and aspects worth considering and give a list of current state-of-the-art tools.},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=21370091&retmode=ref&cmd=prlinks},
uri = {\url{papers3://publication/doi/10.1007/978-1-61779-027-0_15}}
}

@article{Holtgrewe:2011fj,
author = {Holtgrewe, Manuel and Emde, A and Weese, David and Reinert, Knut},
title = {{A Novel And Well-Defined Benchmarking Method For Second Generation Read Mapping}},
journal = {BMC Bioinformatics},
year = {2011},
volume = {12},
number = {1},
pages = {210},
publisher = {BioMed Central Ltd},
affiliation = {Department of Computer Science, Free University of Berlin, Takustr, Germany. holtgrewe@inf.fu-berlin.de},
doi = {10.1186/1471-2105-12-210},
pmid = {21615913},
pmcid = {PMC3128034},
language = {English},
read = {Yes},
rating = {0},
date-added = {2011-06-08T20:42:08GMT},
date-modified = {2015-11-06T12:10:16GMT},
abstract = {Second generation sequencing technologies yield DNA sequence data at ultra high-throughput. Common to most biological applications is a mapping of the reads to an almost identical or highly similar reference genome. The assessment of the quality of read mapping results is not straightforward and has not been formalized so far. Hence, it has not been easy to compare different read mapping approaches in a unified way and to determine which program is the best for what task.We present a new benchmark method, called Rabema (Read Alignment BEnchMArk), for read mappers. It consists of a strict definition of the read mapping problem and of tools to evaluate the result of arbitrary read mappers supporting the SAM output format.We show the usefulness of the benchmark program by performing a comparison of popular read mappers. The tools supporting the benchmark are licensed under the GPL and available from http://www.seqan.de/projects/rabema.html.},
url = {http://www.biomedcentral.com/1471-2105/12/210/abstract},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2011/Holtgrewe/BMC%20Bioinformatics%202011%20Holtgrewe.pdf},
file = {{BMC Bioinformatics 2011 Holtgrewe.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2011/Holtgrewe/BMC Bioinformatics 2011 Holtgrewe.pdf:application/pdf;BMC Bioinformatics 2011 Holtgrewe.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2011/Holtgrewe/BMC Bioinformatics 2011 Holtgrewe.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1186/1471-2105-12-210}}
}

@book{Rausch:2010il,
author = {Rausch, T and Reinert, Knut},
editor = {Heath, Lenwood S and Ramakrishnan, Naren},
title = {{Problem Solving Handbook in Computational Biology and Bioinformatics}},
publisher = {Springer US},
year = {2010},
address = {Boston, MA},
month = oct,
doi = {10.1007/978-0-387-09760-2_2},
isbn = {978-0-387-09759-6},
rating = {0},
date-added = {2011-06-08T20:54:03GMT},
date-modified = {2015-11-06T12:10:05GMT},
abstract = {The problem of comparing multiple sequences is a long-standing brainteaser of molecular biology. The research was sparked by a simple insight: Weak and faint bi- ologically important sequence similarities vanish in a pairwise alignment but stand out in a multiple sequence ...},
url = {http://www.springerlink.com/index/10.1007/978-0-387-09760-2_2},
uri = {\url{papers3://publication/doi/10.1007/978-0-387-09760-2_2}}
}

@article{Bielow:2010cu,
author = {Bielow, Chris and Ruzek, Silke and Huber, Christian G and Reinert, Knut},
title = {{Optimal decharging and clustering of charge ladders generated in ESI-MS.}},
journal = {Journal of Proteome Research},
year = {2010},
volume = {9},
number = {5},
pages = {2688--2695},
month = may,
affiliation = {Institute of Computer Sciences, Free University Berlin, Berlin, Germany. bielow@inf.fu-berlin.de},
doi = {10.1021/pr100177k},
pmid = {20201597},
language = {English},
read = {Yes},
rating = {0},
date-added = {2010-11-22T20:46:11GMT},
date-modified = {2015-11-06T12:10:15GMT},
abstract = {In electrospray ionization mass spectrometry (ESI-MS), peptide and protein ions are usually observed in multiple charge states. Moreover, adduction of the multiply charged species with other ions frequently results in quite complex signal patterns for a single analyte, which significantly complicates the derivation of quantitative information from the mass spectra. Labeling strategies targeting the MS1 level further aggravate this situation, as multiple biological states such as healthy or diseased must be represented simultaneously. We developed an integer linear programming (ILP) approach, which can cluster signals belonging to the same peptide or protein. The algorithm is general in that it models all possible shifts of signals along the m/z axis. These shifts can be induced by different charge states of the compound, the presence of adducts (e.g., potassium or sodium), and/or a fixed mass label (e.g., from ICAT or nicotinic acid labeling), or any combination of the above. We show that our approach can be used to infer more features in labeled data sets, correct wrong charge assignments even in high-resolution MS, improve mass precision, and cluster charged species in different charge states and several adduct types.},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=20201597&retmode=ref&cmd=prlinks},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2010/Bielow/J%20Proteome%20Res%202010%20Bielow.pdf},
file = {{J Proteome Res 2010 Bielow.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2010/Bielow/J Proteome Res 2010 Bielow.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1021/pr100177k}}
}

@article{Emde:2010fw,
author = {Emde, A and Grunert, Marcel and Weese, David and Reinert, Knut and Sperling, Silke R},
title = {{MicroRazerS: rapid alignment of small RNA reads.}},
journal = {Bioinformatics (Oxford, England)},
year = {2010},
volume = {26},
number = {1},
pages = {123--124},
month = jan,
affiliation = {Department of Computer Science, Free University of Berlin, Takustr. 9, Berlin, Germany. emde@inf.fu-berlin.de},
doi = {10.1093/bioinformatics/btp601},
pmid = {19880369},
language = {English},
read = {Yes},
rating = {0},
date-added = {2010-03-24T08:35:42GMT},
date-modified = {2015-11-06T12:10:15GMT},
abstract = {MOTIVATION:Deep sequencing has become the method of choice for determining the small RNA content of a cell. Mapping the sequenced reads onto their reference genome serves as the basis for all further analyses, namely for identification and quantification. A method frequently used is Mega BLAST followed by several filtering steps, even though it is slow and inefficient for this task. Also, none of the currently available short read aligners has established itself for the particular task of small RNA mapping.

RESULTS:We present MicroRazerS, a tool optimized for mapping small RNAs onto a reference genome. It is an order of magnitude faster than Mega BLAST and comparable in speed with other short read mapping tools. In addition, it is more sensitive and easy to handle and adjust.

AVAILABILITY:MicroRazerS is part of the SeqAn C++ library and can be downloaded from http://www.seqan.de/projects/MicroRazerS.html.},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=19880369&retmode=ref&cmd=prlinks},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2010/Emde/Bioinformatics%202010%20Emde.pdf},
file = {{Bioinformatics 2010 Emde.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2010/Emde/Bioinformatics 2010 Emde.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1093/bioinformatics/btp601}}
}

@article{Huser:2010id,
author = {H{\"u}ser, Daniela and Gogol-D{\"o}ring, Andreas and Lutter, Timo and Weger, Stefan and Winter, Kerstin and Hammer, Eva-Maria and Cathomen, Toni and Reinert, Knut and Heilbronn, Regine},
title = {{Integration preferences of wildtype AAV-2 for consensus rep-binding sites at numerous loci in the human genome.}},
journal = {PLoS Pathogens},
year = {2010},
volume = {6},
number = {7},
pages = {e1000985},
affiliation = {Institute of Virology, Campus Benjamin Franklin, Charit{\'e}-Universit{\"a}tsmedizin Berlin, Berlin, Germany.},
doi = {10.1371/journal.ppat.1000985},
pmid = {20628575},
pmcid = {PMC2900306},
language = {English},
read = {Yes},
rating = {0},
date-added = {2010-11-22T20:41:42GMT},
date-modified = {2015-11-06T12:10:15GMT},
abstract = {Adeno-associated virus type 2 (AAV) is known to establish latency by preferential integration in human chromosome 19q13.42. The AAV non-structural protein Rep appears to target a site called AAVS1 by simultaneously binding to Rep-binding sites (RBS) present on the AAV genome and within AAVS1. In the absence of Rep, as is the case with AAV vectors, chromosomal integration is rare and random. For a genome-wide survey of wildtype AAV integration a linker-selection-mediated (LSM)-PCR strategy was designed to retrieve AAV-chromosomal junctions. DNA sequence determination revealed wildtype AAV integration sites scattered over the entire human genome. The bioinformatic analysis of these integration sites compared to those of rep-deficient AAV vectors revealed a highly significant overrepresentation of integration events near to consensus RBS. Integration hotspots included AAVS1 with 10% of total events. Novel hotspots near consensus RBS were identified on chromosome 5p13.3 denoted AAVS2 and on chromsome 3p24.3 denoted AAVS3. AAVS2 displayed seven independent junctions clustered within only 14 bp of a consensus RBS which proved to bind Rep in vitro similar to the RBS in AAVS3. Expression of Rep in the presence of rep-deficient AAV vectors shifted targeting preferences from random integration back to the neighbourhood of consensus RBS at hotspots and numerous additional sites in the human genome. In summary, targeted AAV integration is not as specific for AAVS1 as previously assumed. Rather, Rep targets AAV to integrate into open chromatin regions in the reach of various, consensus RBS homologues in the human genome.},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=20628575&retmode=ref&cmd=prlinks},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2010/H%C3%BCser/PLoS%20Pathog%202010%20H%C3%BCser.pdf},
file = {{PLoS Pathog 2010 Hüser.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2010/Hüser/PLoS Pathog 2010 Hüser.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1371/journal.ppat.1000985}}
}

@book{GogolDoring:2009wx,
author = {Gogol-D{\"o}ring, Andreas and Reinert, Knut},
title = {{Biological sequence analysis using the SeqAn C++ library}},
publisher = {CRC},
year = {2009},
month = oct,
isbn = {9781420076233},
language = {English},
rating = {0},
date-added = {2011-06-08T20:46:19GMT},
date-modified = {2015-11-06T12:10:05GMT},
abstract = {A key to that invaluable resource, this book provides a highly accessible way for the rapid prototyping of algorithms in the field.},
url = {http://books.google.com/books?hl=en&lr=&id=Qf98t1LOiBYC&oi=fnd&pg=PP1&dq=seqan+reinert&ots=4y9iyK_zEv&sig=P6EZHMUrqI1Czy6VqcwgIr4qPBg},
uri = {\url{papers3://publication/uuid/E63A4075-298E-4848-908E-DD78EAB143E5}}
}

@article{Weese:2009iw,
author = {Weese, David and Emde, A and Rausch, T and D{\"o}ring, Andreas and Reinert, Knut},
title = {{RazerS--fast read mapping with sensitivity control.}},
journal = {Genome research},
year = {2009},
volume = {19},
number = {9},
pages = {1646--1654},
month = sep,
affiliation = {Department of Computer Science, Free University of Berlin, 14195 Berlin, Germany. weese@inf.fu-berlin.de},
doi = {10.1101/gr.088823.108},
pmid = {19592482},
pmcid = {PMC2752123},
language = {English},
read = {Yes},
rating = {0},
date-added = {2009-08-14T13:54:02GMT},
date-modified = {2015-11-22T18:57:21GMT},
abstract = {Second-generation sequencing technologies deliver DNA sequence data at unprecedented high throughput. Common to most biological applications is a mapping of the reads to an almost identical or highly similar reference genome. Due to the large amounts of data, efficient algorithms and implementations are crucial for this task. We present an efficient read mapping tool called RazerS. It allows the user to align sequencing reads of arbitrary length using either the Hamming distance or the edit distance. Our tool can work either lossless or with a user-defined loss rate at higher speeds. Given the loss rate, we present an approach that guarantees not to lose more reads than specified. This enables the user to adapt to the problem at hand and provides a seamless tradeoff between sensitivity and running time.},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=19592482&retmode=ref&cmd=prlinks},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2009/Weese/Genome%20Res.%202009%20Weese.pdf},
file = {{Genome Res. 2009 Weese.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2009/Weese/Genome Res. 2009 Weese.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1101/gr.088823.108}}
}

@article{zerck_09_iterative,
author = {Zerck, Alexandra and Nordhoff, Eckhard and Resemann, Anja and Mirgorodskaya, Ekaterina and Suckau, Detlef and Reinert, Knut and Lehrach, Hans and Gobom, Johan},
title = {{An iterative strategy for precursor ion selection for LC - MS/MS based shotgun proteomics}},
journal = {Journal of Proteome Research},
year = {2009},
volume = {8},
number = {7},
pages = {3239--3251},
month = jul,
affiliation = {Max Planck Institute for Molecular Genetics, Department Vertebrate Genomics, Ihnestr. 63-73, D-14195 Berlin, Germany. zerck@molgen.mpg.de},
doi = {10.1021/pr800835x},
pmid = {19402737},
language = {English},
read = {Yes},
rating = {0},
date-added = {2009-08-14T13:55:08GMT},
date-modified = {2015-11-06T12:10:13GMT},
abstract = {Currently, the precursor ion selection strategies in LC-MS mainly choose the most prominent peptide signals for MS/MS analysis. Consequently, high-abundance proteins are identified by MS/MS of many peptides, whereas proteins of lower abundance might elude identification. We present a novel, iterative and result-driven approach for precursor ion selection that significantly increases the efficiency of an MS/MS analysis by decreasing data redundancy and analysis time. By simulating different strategies for precursor ion selection on an existing data set, we compare our method to existing result-driven strategies and evaluate its performance with regard to mass accuracy, database size, and sample complexity.},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=19402737&retmode=ref&cmd=prlinks},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2009/Zerck/J%20Proteome%20Res%202009%20Zerck.pdf},
file = {{J Proteome Res 2009 Zerck.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2009/Zerck/J Proteome Res 2009 Zerck.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1021/pr800835x}}
}

@article{Bauer:2009ji,
author = {Bauer, Raphael Andr{\'e} and Rother, Kristian and Moor, Peter and Reinert, Knut and Steinke, Thomas and Bujnicki, Janusz M and Preissner, Robert},
title = {{Fast Structural Alignment of Biomolecules Using a Hash Table, N-Grams and String Descriptors}},
journal = {Algorithms},
year = {2009},
volume = {2},
number = {2},
pages = {692--709},
month = jun,
publisher = {Molecular Diversity Preservation International},
doi = {10.3390/a2020692},
language = {English},
read = {Yes},
rating = {0},
date-added = {2011-06-08T20:48:18GMT},
date-modified = {2015-11-06T12:10:16GMT},
abstract = {This work presents a generalized approach for the fast structural alignment of thousands of macromolecular structures. The method uses string representations of a macromolecular structure and a hash table that stores n-grams of a certain size for searching. To this end, macromolecular structure-to-string translators were implemented for protein and RNA structures. A query against the index is performed in two hierarchical steps to unite speed and precision. In the first step the query structure is translated into n-grams, and all target structures containing these n-grams are retrieved from the hash table. In the second step all corresponding n-grams of the query and each target structure are subsequently aligned, and after each alignment a score is calculated based on the matching n-grams of query and target. The extendable framework enables the user to query and structurally align thousands of protein and RNA structures on a commodity machine and is available as open source from http://lajolla.sf.net.},
url = {http://www.mdpi.com/1999-4893/2/2/692/},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2009/Bauer/Algorithms%202009%20Bauer.pdf},
file = {{Algorithms 2009 Bauer.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2009/Bauer/Algorithms 2009 Bauer.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.3390/a2020692}}
}

@article{Rausch:2009hq,
author = {Rausch, T and Koren, Sergey and Denisov, G and Weese, David and Emde, A and D{\"o}ring, Andreas and Reinert, Knut},
title = {{A consistency-based consensus algorithm for de novo and reference-guided sequence assembly of short reads.}},
journal = {Bioinformatics (Oxford, England)},
year = {2009},
volume = {25},
number = {9},
pages = {1118--1124},
month = may,
affiliation = {International Max Planck Research School for Computational Biology and Scientific Computing, Ihnestr. 63-73, Algorithmische Bioinformatik, Institut f{\"u}r Informatik, Takustr. 9, 14195 Berlin, Germany. rausch@inf.fu-berlin.de},
doi = {10.1093/bioinformatics/btp131},
pmid = {19269990},
pmcid = {PMC2732307},
language = {English},
read = {Yes},
rating = {0},
date-added = {2009-03-11T08:51:34GMT},
date-modified = {2015-11-06T12:10:12GMT},
abstract = {MOTIVATION:Novel high-throughput sequencing technologies pose new algorithmic challenges in handling massive amounts of short-read, high-coverage data. A robust and versatile consensus tool is of particular interest for such data since a sound multi-read alignment is a prerequisite for variation analyses, accurate genome assemblies and insert sequencing.

RESULTS:A multi-read alignment algorithm for de novo or reference-guided genome assembly is presented. The program identifies segments shared by multiple reads and then aligns these segments using a consistency-enhanced alignment graph. On real de novo sequencing data obtained from the newly established NCBI Short Read Archive, the program performs similarly in quality to other comparable programs. On more challenging simulated datasets for insert sequencing and variation analyses, our program outperforms the other tools.

AVAILABILITY:The consensus program can be downloaded from http://www.seqan.de/projects/consensus.html. It can be used stand-alone or in conjunction with the Celera Assembler. Both application scenarios as well as the usage of the tool are described in the documentation.},
url = {http://bioinformatics.oxfordjournals.org/cgi/content/short/25/9/1118},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2009/Rausch/Bioinformatics%202009%20Rausch.pdf},
file = {{Bioinformatics 2009 Rausch.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2009/Rausch/Bioinformatics 2009 Rausch.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1093/bioinformatics/btp131}}
}

@article{Lenhof:2009bq,
author = {Lenhof, Hans-Peter and Reinert, Knut and Vingron, Martin},
title = {{A Polyhedral Approach to RNA Sequence Structure Alignment}},
journal = {dx.doi.org},
year = {2009},
volume = {5},
number = {3},
pages = {517--530},
month = mar,
doi = {10.1089/cmb.1998.5.517},
language = {English},
rating = {0},
date-added = {2015-09-08T22:50:19GMT},
date-modified = {2015-11-26T15:38:49GMT},
abstract = {ABSTRACT Ribonucleic acid (RNA) is a polymer composed of four bases denoted A, C, G, and U. It generally is a single-stranded molecule where the bases form hydrogen bonds within the same molecule leading to structure formation. In comparing different homologous RNA molecules it is important to consider both the base sequence and the structure of the molecules. Traditional alignment algorithms can only account for the sequence of bases, but not for the base pairings. Considering the structure leads to significant computational problems because of the dependencies introduced by the base pairings. In this paper we address the problem of optimally aligning a given RNA sequence of unknown structure to one of known sequence and structure. We phrase the problem as an integer linear program and then solve it using methods from polyhedral combinatorics. In our computational experiments we could solve large problem instances{\textemdash}23S ribosomal RNA with more than 1400 bases{\textemdash}a size intractable for former algorithms.},
url = {http://www.liebertonline.com/doi/abs/10.1089/cmb.1998.5.517},
uri = {\url{papers3://publication/doi/10.1089/cmb.1998.5.517}}
}

@incollection{Rausch2009,
author = {Rausch, T and Reinert, Knut},
title = {{The problem solving handbook for computational biology and bioinformatics}},
year = {2009},
editor = {Heath, L S and Ramakrishnan, N},
publisher = {Springer},
rating = {0},
date-added = {2013-09-04T14:04:09GMT},
date-modified = {2015-07-12T09:51:09GMT},
uri = {\url{papers3://publication/uuid/A9C736AD-428B-4BD0-9E47-9FEBC190E3A9}}
}

@article{SchulzTrieglaff:2009cq,
author = {Schulz-Trieglaff, Ole and Machtejevas, Egidijus and Reinert, Knut and Schl{\"u}ter, Hartmut and Thiemann, Joachim and Unger, Klaus},
title = {{Statistical quality assessment and outlier detection for liquid chromatography-mass spectrometry experiments.}},
journal = {BioData mining},
year = {2009},
volume = {2},
number = {1},
pages = {4},
affiliation = {International Max Planck Research School for Computational Biology and Scientific Computing, Berlin, Germany. trieglaf@inf.fu-berlin.de},
doi = {10.1186/1756-0381-2-4},
pmid = {19351414},
pmcid = {PMC2678124},
language = {English},
read = {Yes},
rating = {0},
date-added = {2009-06-22T07:13:38GMT},
date-modified = {2015-11-06T12:10:13GMT},
abstract = {BACKGROUND:Quality assessment methods, that are common place in engineering and industrial production, are not widely spread in large-scale proteomics experiments. But modern technologies such as Multi-Dimensional Liquid Chromatography coupled to Mass Spectrometry (LC-MS) produce large quantities of proteomic data. These data are prone to measurement errors and reproducibility problems such that an automatic quality assessment and control become increasingly important.

RESULTS:We propose a methodology to assess the quality and reproducibility of data generated in quantitative LC-MS experiments. We introduce quality descriptors that capture different aspects of the quality and reproducibility of LC-MS data sets. Our method is based on the Mahalanobis distance and a robust Principal Component Analysis.

CONCLUSION:We evaluate our approach on several data sets of different complexities and show that we are able to precisely detect LC-MS runs of poor signal quality in large-scale studies.},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=19351414&retmode=ref&cmd=prlinks},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2009/Schulz-Trieglaff/BioData%20Min%202009%20Schulz-Trieglaff.pdf},
file = {{BioData Min 2009 Schulz-Trieglaff.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2009/Schulz-Trieglaff/BioData Min 2009 Schulz-Trieglaff.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1186/1756-0381-2-4}}
}

@incollection{Rausch2009,
author = {Rausch, T and Reinert, Knut},
title = {{The problem solving handbook for computational biology and bioinformatics}},
year = {2009},
editor = {Heath, L S and Ramakrishnan, N},
publisher = {Springer},
rating = {0},
date-added = {2013-09-13T13:08:27GMT},
date-modified = {2015-07-12T09:51:09GMT},
uri = {\url{papers3://publication/uuid/82E8C1CD-703D-440D-AA9B-A302D066BBFC}}
}

@article{Emde:2009wq,
author = {Emde, A and Rausch, T and D{\"o}ring, Andreas and Reinert, Knut},
title = {{RazerS{\textemdash}fast read mapping with sensitivity control}},
journal = {Genome {\ldots}},
year = {2009},
rating = {0},
date-added = {2015-09-08T22:50:00GMT},
date-modified = {2015-11-26T15:38:49GMT},
abstract = {Abstract Second-generation sequencing technologies deliver DNA sequence data at unprecedented high throughput. Common to most biological applications is a mapping of the reads to an almost identical or highly similar reference genome. Due to the large ... 
},
url = {http://genome.cshlp.org/content/19/9/1646.short},
uri = {\url{papers3://publication/uuid/FF1EEB49-88E0-4C15-B291-F9A5F896E20C}}
}

@article{Ponten:2009wf,
author = {Ponten, F and Radbruch, A and Reinert, Knut},
title = {{Approaching clinical proteomics: current state and future fields of application in fluid proteomics}},
journal = {Clinical Chemistry and {\ldots}},
year = {2009},
rating = {0},
date-added = {2015-09-08T22:50:01GMT},
date-modified = {2015-11-26T15:38:49GMT},
abstract = {Abstract The field of clinical proteomics offers opportunities to identify new disease biomarkers in body fluids, cells and tissues. These biomarkers can be used in clinical applications for diagnosis, stratification of patients for specific treatment, or therapy ... 
},
url = {http://www.degruyter.com/view/j/cclm.2009.47.issue-6/cclm.2009.167/cclm.2009.167.xml},
uri = {\url{papers3://publication/uuid/87075DA1-B616-4AD8-BCC5-3C2858BF3228}}
}

@article{Rausch:2008bk,
author = {Rausch, T and Emde, A and Weese, David and D{\"o}ring, Andreas and Notredame, C and Reinert, Knut},
title = {{Segment-based multiple sequence alignment.}},
journal = {Bioinformatics (Oxford, England)},
year = {2008},
volume = {24},
number = {16},
pages = {i187--192},
month = aug,
affiliation = {International Max Planck Research School for Computational Biology and Scientific Computing, Ihnestr 63-73, 14195 Berlin, Germany. rausch@inf.fu-berlin.de},
doi = {10.1093/bioinformatics/btn281},
pmid = {18689823},
language = {English},
read = {Yes},
rating = {0},
date-added = {2008-10-31T11:26:05GMT},
date-modified = {2015-11-06T12:10:11GMT},
abstract = {MOTIVATION:Many multiple sequence alignment tools have been developed in the past, progressing either in speed or alignment accuracy. Given the importance and wide-spread use of alignment tools, progress in both categories is a contribution to the community and has driven research in the field so far.

RESULTS:We introduce a graph-based extension to the consistency-based, progressive alignment strategy. We apply the consistency notion to segments instead of single characters. The main problem we solve in this context is to define segments of the sequences in such a way that a graph-based alignment is possible. We implemented the algorithm using the SeqAn library and report results on amino acid and DNA sequences. The benefit of our approach is threefold: (1) sequences with conserved blocks can be rapidly aligned, (2) the implementation is conceptually easy, generic and fast and (3) the consistency idea can be extended to align multiple genomic sequences.

AVAILABILITY:The segment-based multiple sequence alignment tool can be downloaded from http://www.seqan.de/projects/msa.html. A novel version of T-Coffee interfaced with the tool is available from http://www.tcoffee.org. The usage of the tool is described in both documentations.},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=18689823&retmode=ref&cmd=prlinks},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2008/Rausch/Bioinformatics%202008%20Rausch.pdf},
file = {{Bioinformatics 2008 Rausch.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2008/Rausch/Bioinformatics 2008 Rausch.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1093/bioinformatics/btn281}}
}

@article{Sturm:2008eu,
author = {Bertsch, A and Sturm, Marc and Gr{\"o}pl, Clemens and Hildebrandt, Andreas and Hussong, Rene and Lange, Eva and Pfeifer, Nico and Schulz-Trieglaff, Ole and Zerck, Alexandra and Reinert, Knut and Kohlbacher, Oliver},
title = {{OpenMS - an open-source software framework for mass spectrometry.}},
journal = {BMC Bioinformatics},
year = {2008},
volume = {9},
pages = {163},
affiliation = {Center for Bioinformatics, Eberhard Karls University T{\"u}bingen, Sand 14, 72076 T{\"u}bingen, Germany. sturm@informatik.uni-tuebingen.de},
doi = {10.1186/1471-2105-9-163},
pmid = {18366760},
pmcid = {PMC2311306},
language = {English},
rating = {5},
date-added = {2008-03-31T00:53:33GMT},
date-modified = {2015-11-06T12:10:09GMT},
abstract = {BACKGROUND:Mass spectrometry is an essential analytical technique for high-throughput analysis in proteomics and metabolomics. The development of new separation techniques, precise mass analyzers and experimental protocols is a very active field of research. This leads to more complex experimental setups yielding ever increasing amounts of data. Consequently, analysis of the data is currently often the bottleneck for experimental studies. Although software tools for many data analysis tasks are available today, they are often hard to combine with each other or not flexible enough to allow for rapid prototyping of a new analysis workflow.

RESULTS:We present OpenMS, a software framework for rapid application development in mass spectrometry. OpenMS has been designed to be portable, easy-to-use and robust while offering a rich functionality ranging from basic data structures to sophisticated algorithms for data analysis. This has already been demonstrated in several studies.

CONCLUSION:OpenMS is available under the Lesser GNU Public License (LGPL) from the project website at http://www.openms.de.},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=18366760&retmode=ref&cmd=prlinks},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2008/Bertsch/BMC%20Bioinformatics%202008%20Bertsch.pdf},
file = {{BMC Bioinformatics 2008 Bertsch.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2008/Bertsch/BMC Bioinformatics 2008 Bertsch.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1186/1471-2105-9-163}}
}

@article{doring_08_seqan,
author = {D{\"o}ring, Andreas and Weese, David and Rausch, T and Reinert, Knut},
title = {{SeqAn an efficient, generic C++ library for sequence analysis.}},
journal = {BMC Bioinformatics},
year = {2008},
volume = {9},
number = {1},
pages = {11},
publisher = {BioMed Central Ltd},
affiliation = {Algorithmische Bioinformatik, Institut f{\"u}r Informatik, Takustr, 9, 14195 Berlin, Germany. doering@inf.fu-berlin.de},
doi = {10.1186/1471-2105-9-11},
pmid = {18184432},
pmcid = {PMC2246154},
language = {English},
read = {Yes},
rating = {0},
date-added = {2009-11-24T15:28:08GMT},
date-modified = {2015-11-22T18:55:27GMT},
abstract = {BACKGROUND:The use of novel algorithmic techniques is pivotal to many important problems in life science. For example the sequencing of the human genome 1 would not have been possible without advanced assembly algorithms. However, owing to the high speed of technological progress and the urgent need for bioinformatics tools, there is a widening gap between state-of-the-art algorithmic techniques and the actual algorithmic components of tools that are in widespread use.

RESULTS:To remedy this trend we propose the use of SeqAn, a library of efficient data types and algorithms for sequence analysis in computational biology. SeqAn comprises implementations of existing, practical state-of-the-art algorithmic components to provide a sound basis for algorithm testing and development. In this paper we describe the design and content of SeqAn and demonstrate its use by giving two examples. In the first example we show an application of SeqAn as an experimental platform by comparing different exact string matching algorithms. The second example is a simple version of the well-known MUMmer tool rewritten in SeqAn. Results indicate that our implementation is very efficient and versatile to use.

CONCLUSION:We anticipate that SeqAn greatly simplifies the rapid development of new bioinformatics tools by providing a collection of readily usable, well-designed algorithmic components which are fundamental for the field of sequence analysis. This leverages not only the implementation of new algorithms, but also enables a sound analysis and comparison of existing algorithms.},
url = {http://www.biomedcentral.com/1471-2105/9/11},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2008/oring/BMC%20Bioinformatics%202008%20oring.pdf},
file = {{BMC Bioinformatics 2008 oring.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2008/oring/BMC Bioinformatics 2008 oring.pdf:application/pdf;BMC Bioinformatics 2008 oring.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2008/oring/BMC Bioinformatics 2008 oring.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1186/1471-2105-9-11}}
}

@article{SchulzTrieglaff:2008gx,
author = {Schulz-Trieglaff, Ole and Pfeifer, Nico and Gr{\"o}pl, Clemens and Kohlbacher, Oliver and Reinert, Knut},
title = {{LC-MSsim--a simulation software for liquid chromatography mass spectrometry data.}},
journal = {BMC Bioinformatics},
year = {2008},
volume = {9},
pages = {423},
affiliation = {International Max Planck Research School for Computational Biology and Scientific Computing, Berlin, Germany. trieglaf@inf.fu-berlin.de},
doi = {10.1186/1471-2105-9-423},
pmid = {18842122},
pmcid = {PMC2577660},
language = {English},
read = {Yes},
rating = {0},
date-added = {2008-11-03T18:00:18GMT},
date-modified = {2015-12-02T11:13:23GMT},
abstract = {BACKGROUND:Mass Spectrometry coupled to Liquid Chromatography (LC-MS) is commonly used to analyze the protein content of biological samples in large scale studies. The data resulting from an LC-MS experiment is huge, highly complex and noisy. Accordingly, it has sparked new developments in Bioinformatics, especially in the fields of algorithm development, statistics and software engineering. In a quantitative label-free mass spectrometry experiment, crucial steps are the detection of peptide features in the mass spectra and the alignment of samples by correcting for shifts in retention time. At the moment, it is difficult to compare the plethora of algorithms for these tasks. So far, curated benchmark data exists only for peptide identification algorithms but no data that represents a ground truth for the evaluation of feature detection, alignment and filtering algorithms.

RESULTS:We present LC-MSsim, a simulation software for LC-ESI-MS experiments. It simulates ESI spectra on the MS level. It reads a list of proteins from a FASTA file and digests the protein mixture using a user-defined enzyme. The software creates an LC-MS data set using a predictor for the retention time of the peptides and a model for peak shapes and elution profiles of the mass spectral peaks. Our software also offers the possibility to add contaminants, to change the background noise level and includes a model for the detectability of peptides in mass spectra. After the simulation, LC-MSsim writes the simulated data to mzData, a public XML format. The software also stores the positions (monoisotopic m/z and retention time) and ion counts of the simulated ions in separate files.

CONCLUSION:LC-MSsim generates simulated LC-MS data sets and incorporates models for peak shapes and contaminations. Algorithm developers can match the results of feature detection and alignment algorithms against the simulated ion lists and meaningful error rates can be computed. We anticipate that LC-MSsim will be useful to the wider community to perform benchmark studies and comparisons between computational tools.},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=18842122&retmode=ref&cmd=prlinks},
uri = {\url{papers3://publication/doi/10.1186/1471-2105-9-423}}
}

@article{Bauer:2008vj,
author = {Bauer, M and Klau, Gunnar W and Reinert, Knut},
title = {{An Exact Mathematical Programming Approach to Multiple RNA Sequence-Structure Alignment}},
journal = {Algorithmic Operations Research},
year = {2008},
volume = {3},
pages = {130--146},
read = {Yes},
rating = {0},
date-added = {2008-11-17T09:46:24GMT},
date-modified = {2015-11-24T06:38:52GMT},
abstract = {...  An  Exact  Mathematical  Programming  Approach to Multiple  RNA  Sequence - Structure  Alignment Markus Bauer, Gunnar W. Klau, and Knut Reinert ... 1 Page 2. AN  EXACT  MATHEMATICAL PROGRAMMING  APPROACH TO MULTIPLE  RNA  SEQUENCE - STRUCTURE  ALIGNMENT  ...},
url = {http://page.mi.fu-berlin.de/gunnar/pubs/mlara_AOR_preprint.pdf},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2008/Bauer/2008%20Bauer.pdf},
file = {{2008 Bauer.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2008/Bauer/2008 Bauer.pdf:application/pdf}},
uri = {\url{papers3://publication/uuid/F53CE52B-1DCE-4903-8656-4AC120353BE6}}
}

@article{Rausch:2008ws,
author = {Rausch, T and Emde, A and Reinert, Knut},
title = {{Robust consensus computation}},
journal = {BMC Bioinformatics},
year = {2008},
volume = {9},
number = {Suppl 10},
pages = {P4},
rating = {0},
date-added = {2013-09-04T14:04:14GMT},
date-modified = {2015-11-06T12:10:22GMT},
abstract = { BMC Bioinformatics Open Access Poster presentation   computation Tobias * 1,2 , Anne-Katrin Emde 1,2 and Knut  2 },
url = {http://www.biomedcentral.com/content/pdf/1471-2105-9-s10-p4.pdf},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2008/Rausch/BMC%20Bioinformatics%202008%20Rausch.pdf},
file = {{BMC Bioinformatics 2008 Rausch.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2008/Rausch/BMC Bioinformatics 2008 Rausch.pdf:application/pdf}},
uri = {\url{papers3://publication/uuid/BE347016-88AA-4642-81DC-E1EE604F9E2E}}
}

@article{SchulzTrieglaff:2008wp,
author = {Schulz-Trieglaff, Ole and Hussong, Rene and Gr{\"o}pl, Clemens and Leinenbach, Andreas and Hildebrandt, Andreas and Huber, Christian and Reinert, Knut},
title = {{Computational quantification of peptides from LC-MS data.}},
journal = {Journal of Computational Biology},
year = {2008},
volume = {15},
number = {7},
pages = {685--704},
affiliation = {International Max Planck Research School for Computational Biology and Scientific Computing, Department of Mathematics and Computer Science, Free University Berlin, Berlin, Germany. trieglaf@inf.fu-berlin.de},
doi = {10.1089/cmb.2007.0117},
pmid = {18707556},
language = {English},
rating = {0},
date-added = {2010-09-15T07:26:08GMT},
date-modified = {2015-11-06T12:10:15GMT},
abstract = {Liquid chromatography coupled to mass spectrometry (LC-MS) has become a major tool for the study of biological processes. High-throughput LC-MS experiments are frequently conducted in modern laboratories, generating an enormous amount of data per day. A manual inspection is therefore no longer a feasible task. Consequently, there is a need for computational tools that can rapidly provide information about mass, elution time, and abundance of the compounds in a LC-MS sample. We present an algorithm for the detection and quantification of peptides in LC-MS data. Our approach is flexible and independent of the MS technology in use. It is based on a combination of the sweep line paradigm with a novel wavelet function tailored to detect isotopic patterns of peptides. We propose a simple voting schema to use the redundant information in consecutive scans for an accurate determination of monoisotopic masses and charge states. By explicitly modeling the instrument inaccuracy, we are also able to cope with data sets of different quality and resolution. We evaluate our technique on data from different instruments and show that we can rapidly estimate mass, centroid of retention time, and abundance of peptides in a sound algorithmic framework. Finally, we compare the performance of our method to several other techniques on three data sets of varying complexity.},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=18707556&retmode=ref&cmd=prlinks},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2008/Schulz-Trieglaff/Journal%20of%20Computational%20Biology%202008%20Schulz-Trieglaff.pdf},
file = {{Journal of Computational Biology 2008 Schulz-Trieglaff.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2008/Schulz-Trieglaff/Journal of Computational Biology 2008 Schulz-Trieglaff.pdf:application/pdf;Journal of Computational Biology 2008 Schulz-Trieglaff.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2008/Schulz-Trieglaff/Journal of Computational Biology 2008 Schulz-Trieglaff.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1089/cmb.2007.0117}}
}

@inproceedings{Weese:2008wj,
author = {Schulz, Marcel H and Weese, David and Rausch, T and ring, A D o and Reinert, Knut and Vingron, Martin},
title = {{Fast and adaptive variable order Markov Chain construction}},
booktitle = {Proc. 8th International Workshop on Algorithms in Bioinformatics},
year = {2008},
pages = {306--317},
publisher = {Springer-Verlag},
read = {Yes},
rating = {0},
date-added = {2013-09-13T13:08:26GMT},
date-modified = {2015-11-06T12:10:23GMT},
abstract = { 73, 14195 Berlin, Germany {marcel. ,martin.vingron}@molgen.mpg.de 2 Department of  9, 14195 Berlin, Germany { ,rausch,doering, }@inf.fu },
url = {http://www.springerlink.com/index/w786686m07554mw2.pdf},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2008/Schulz/2008%20Schulz.pdf},
file = {{2008 Schulz.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2008/Schulz/2008 Schulz.pdf:application/pdf}},
uri = {\url{papers3://publication/uuid/74AC9353-717D-46B7-8C48-4429267D54D7}}
}

@article{Bauer:2007im,
author = {Bauer, M and Klau, Gunnar W and Reinert, Knut},
title = {{Accurate multiple sequence-structure alignment of RNA sequences using combinatorial optimization}},
journal = {BMC Bioinformatics},
year = {2007},
volume = {8},
number = {1},
pages = {271},
month = jul,
publisher = {BioMed Central Ltd},
affiliation = {Department of Mathematics and Computer Science, Free University Berlin, Berlin, Germany. mbauer@inf.fu-berlin.de},
doi = {10.1186/1471-2105-8-271},
pmid = {17662141},
pmcid = {PMC1955456},
language = {English},
read = {Yes},
rating = {0},
date-added = {2015-09-08T22:50:07GMT},
date-modified = {2015-11-29T12:46:58GMT},
abstract = {The discovery of functional non-coding RNA sequences has led to an increasing interest in algorithms related to RNA analysis. Traditional sequence alignment algorithms, however, fail at computing reliable alignments of low-homology RNA sequences. The spatial conformation of RNA sequences largely determines their function, and therefore RNA alignment algorithms have to take structural information into account.},
url = {http://www.biomedcentral.com/1471-2105/8/271},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Files/1C/1C905BC3-8AB5-49A0-9A47-931DB23D7F06},
file = {{1C905BC3-8AB5-49A0-9A47-931DB23D7F06:/Users/reinert/Dropbox/Library.papers3/Files/1C/1C905BC3-8AB5-49A0-9A47-931DB23D7F06:application/pdf}},
uri = {\url{papers3://publication/doi/10.1186/1471-2105-8-271}}
}

@article{lange_07_geometric,
author = {Lange, Eva and Gr{\"o}pl, Clemens and Schulz-Trieglaff, Ole and Leinenbach, Andreas and Huber, Christian and Reinert, Knut},
title = {{A geometric approach for the alignment of liquid chromatography-mass spectrometry data.}},
journal = {Bioinformatics (Oxford, England)},
year = {2007},
volume = {23},
number = {13},
pages = {i273--i281},
month = jul,
affiliation = {Free University Berlin, Department of Mathematics and Computer Science, Berlin, Germany. lange@inf.fu-berlin.de},
doi = {10.1093/bioinformatics/btm209},
pmid = {17646306},
language = {English},
read = {Yes},
rating = {0},
date-added = {2008-03-10T22:05:06GMT},
date-modified = {2015-11-06T12:10:06GMT},
abstract = {MOTIVATION:Liquid chromatography coupled to mass spectrometry (LC-MS) and combined with tandem mass spectrometry (LC-MS/MS) have become a prominent tool for the analysis of complex proteomic samples. An important step in a typical workflow is the combination of results from multiple LC-MS experiments to improve confidence in the obtained measurements or to compare results from different samples. To do so, a suitable mapping or alignment between the data sets needs to be estimated. The alignment has to correct for variations in mass and elution time which are present in all mass spectrometry experiments.

RESULTS:We propose a novel algorithm to align LC-MS samples and to match corresponding ion species across samples. Our algorithm matches landmark signals between two data sets using a geometric technique based on pose clustering. Variations in mass and retention time are corrected by an affine dewarping function estimated from matched landmarks. We use the pairwise dewarping in an algorithm for aligning multiple samples. We show that our pose clustering approach is fast and reliable as compared to previous approaches. It is robust in the presence of noise and able to accurately align samples with only few common ion species. In addition, we can easily handle different kinds of LC-MS data and adopt our algorithm to new mass spectrometry technologies.

AVAILABILITY:This algorithm is implemented as part of the OpenMS software library for shotgun proteomics and available under the Lesser GNU Public License (LGPL) at www.openms.de.},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=17646306&retmode=ref&cmd=prlinks},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2007/Lange/Bioinformatics%202007%20Lange.pdf},
file = {{Bioinformatics 2007 Lange.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2007/Lange/Bioinformatics 2007 Lange.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1093/bioinformatics/btm209}}
}

@inproceedings{Reinert:2007wa,
author = {Reinert, Knut and Bauer, M and D{\"o}ring, Andreas and Klau, Gunnar W},
title = {{A general paradigm for fast, adaptive clustering of biological sequences}},
booktitle = {subs.emis.de},
year = {2007},
month = jun,
read = {Yes},
rating = {0},
date-added = {2010-06-17T14:18:49GMT},
date-modified = {2015-11-06T12:10:15GMT},
abstract = {Abstract: There are numerous methods that compute clusterings of biological sequences based on pairwise distances. This necessitates the computation of O(n2) sequence comparisons. Users usually want to apply the most sensitive distance measure which normally is the most ...},
url = {http://subs.emis.de/LNI/Proceedings/Proceedings115/gi-proc-115-003.pdf},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2007/Reinert/2007%20Reinert.pdf},
file = {{2007 Reinert.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2007/Reinert/2007 Reinert.pdf:application/pdf}},
uri = {\url{papers3://publication/uuid/B05F1314-E2D0-4F1F-BC77-85332D9917BD}}
}

@article{Klau:2007fu,
author = {Klau, Gunnar W and Rahmann, Sven and Schliep, Alexander and Reinert, Knut},
title = {{Integer linear programming approaches for non-unique probe selection}},
journal = {Discrete Applied Mathematics},
year = {2007},
volume = {155},
number = {6-7},
pages = {840--856},
month = apr,
doi = {10.1016/j.dam.2005.09.021},
read = {Yes},
rating = {0},
date-added = {2008-03-10T22:05:53GMT},
date-modified = {2015-11-06T12:10:06GMT},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2007/Klau/Discrete%20Applied%20Mathematics%202007%20Klau.pdf},
file = {{Discrete Applied Mathematics 2007 Klau.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2007/Klau/Discrete Applied Mathematics 2007 Klau.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1016/j.dam.2005.09.021}}
}

@article{Kohlbacher:2007fc,
author = {Kohlbacher, Oliver and Reinert, Knut and Gr{\"o}pl, Clemens and Lange, Eva and Pfeifer, Nico and Schulz-Trieglaff, Ole and Sturm, Marc},
title = {{TOPP--the OpenMS proteomics pipeline.}},
journal = {Bioinformatics (Oxford, England)},
year = {2007},
volume = {23},
number = {2},
pages = {e191--7},
month = jan,
affiliation = {Simulation of Biological Systems, Eberhard Karls University T{\"u}bingen Sand 14, 72076 T{\"u}bingen, Germany. oliver.kohlbacher@uni-tuebingen.de},
doi = {10.1093/bioinformatics/btl299},
pmid = {17237091},
language = {English},
rating = {0},
date-added = {2008-03-10T22:06:37GMT},
date-modified = {2015-11-06T12:10:06GMT},
abstract = {MOTIVATION:Experimental techniques in proteomics have seen rapid development over the last few years. Volume and complexity of the data have both been growing at a similar rate. Accordingly, data management and analysis are one of the major challenges in proteomics. Flexible algorithms are required to handle changing experimental setups and to assist in developing and validating new methods. In order to facilitate these studies, it would be desirable to have a flexible 'toolbox' of versatile and user-friendly applications allowing for rapid construction of computational workflows in proteomics.

RESULTS:We describe a set of tools for proteomics data analysis-TOPP, The OpenMS Proteomics Pipeline. TOPP provides a set of computational tools which can be easily combined into analysis pipelines even by non-experts and can be used in proteomics workflows. These applications range from useful utilities (file format conversion, peak picking) over wrapper applications for known applications (e.g. Mascot) to completely new algorithmic techniques for data reduction and data analysis. We anticipate that TOPP will greatly facilitate rapid prototyping of proteomics data evaluation pipelines. As such, we describe the basic concepts and the current abilities of TOPP and illustrate these concepts in the context of two example applications: the identification of peptides from a raw dataset through database search and the complex analysis of a standard addition experiment for the absolute quantitation of biomarkers. The latter example demonstrates TOPP's ability to construct flexible analysis pipelines in support of complex experimental setups.

AVAILABILITY:The TOPP components are available as open-source software under the lesser GNU public license (LGPL). Source code is available from the project website at www.OpenMS.de},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=17237091&retmode=ref&cmd=prlinks},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2007/Kohlbacher/Bioinformatics%202007%20Kohlbacher.pdf},
file = {{Bioinformatics 2007 Kohlbacher.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2007/Kohlbacher/Bioinformatics 2007 Kohlbacher.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1093/bioinformatics/btl299}}
}

@article{SchulzTrieglaff:2007tq,
author = {Schulz-Trieglaff, Ole and Hussong, Rene and Gr{\"o}pl, Clemens and Reinert, Knut},
title = {{A Fast and Accurate Algorithm for the Quantification of Peptides from Mass Spectrometry Data}},
journal = {Proceedings of the Eleventh Annual International Conference {\ldots}},
year = {2007},
read = {Yes},
rating = {0},
date-added = {2008-03-10T22:04:09GMT},
date-modified = {2015-11-06T12:10:06GMT},
abstract = {Abstract. Liquid chromatography combined with mass spectrometry (LC-MS) has become the prevalent technology in high-throughput pro- teomics research. One of the aims of this discipline is to obtain accurate quantitative information },
url = {http://www.springerlink.com/index/y7n4593123531572.pdf},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2007/Schulz-Trieglaff/Proceedings%20of%20the%20Eleventh%20Annual%20International%20Conference%20%E2%80%A6%202007%20Schulz-Trieglaff.pdf},
file = {{Proceedings of the Eleventh Annual International Conference … 2007 Schulz-Trieglaff.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2007/Schulz-Trieglaff/Proceedings of the Eleventh Annual International Conference … 2007 Schulz-Trieglaff.pdf:application/pdf}},
uri = {\url{papers3://publication/uuid/6E4959E3-40E7-404D-970D-16BD0E47496A}}
}

@article{Kohlbacher:2007wv,
author = {Kohlbacher, Oliver and Reinert, Knut and Gr{\"o}pl, Clemens and Lange, Eva},
title = {{TOPP{\textemdash}the OpenMS proteomics pipeline}},
journal = {{\ldots}},
year = {2007},
rating = {0},
date-added = {2015-09-08T22:50:08GMT},
date-modified = {2015-11-26T15:38:49GMT},
abstract = {Abstract Motivation: Experimental techniques in proteomics have seen rapid development over the last few years. Volume and complexity of the data have both been growing at a similar rate. Accordingly, data management and analysis are one of the major challenges ... 
},
url = {http://bioinformatics.oxfordjournals.org/content/23/2/e191.short},
uri = {\url{papers3://publication/uuid/A1DFB1CD-7FA8-43B1-8CDF-E6380B2FE99B}}
}

@article{Bauer:2007uj,
author = {Bauer, M and Klau, Gunnar W and Reinert, Knut},
title = {{Accurate multiple sequence-structure alignment of RNA sequences using combinatorial optimization}},
journal = {BMC Bioinformatics},
year = {2007},
pmid = {17662141},
pmcid = {PMC1955456},
read = {Yes},
rating = {0},
date-added = {2008-03-31T02:42:41GMT},
date-modified = {2015-11-22T18:57:04GMT},
url = {http://www.biomedcentral.com/content/pdf/1471-2105-8-271.pdf},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2007/Bauer/BMC%20Bioinformatics%202007%20Bauer.pdf},
file = {{BMC Bioinformatics 2007 Bauer.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2007/Bauer/BMC Bioinformatics 2007 Bauer.pdf:application/pdf}},
uri = {\url{papers3://publication/uuid/C1E986CC-7845-4095-8BD6-F2D432340C4F}}
}

@article{Mayr:2006if,
author = {Mayr, Bettina M and Kohlbacher, Oliver and Reinert, Knut and Sturm, Marc and Gr{\"o}pl, Clemens and Lange, Eva and Klein, Christoph and Huber, Christian G},
title = {{Absolute myoglobin quantitation in serum by combining two-dimensional liquid chromatography-electrospray ionization mass spectrometry and novel data analysis algorithms.}},
journal = {Journal of Proteome Research},
year = {2006},
volume = {5},
number = {2},
pages = {414--421},
month = feb,
affiliation = {Department of Chemistry, Instrumental Analysis and Bioanalysis, Saarland University, 66123 Saarbr{\"u}cken, Germany.},
doi = {10.1021/pr050344u},
pmid = {16457608},
language = {English},
read = {Yes},
rating = {0},
date-added = {2008-03-10T22:08:38GMT},
date-modified = {2015-11-06T12:10:06GMT},
abstract = {To measure myoglobin, a marker for myocardial infarction, directly in human serum, two-dimensional liquid chromatography in combination with electrospray ionization mass spectrometry was applied as an analytical method. High-abundant serum proteins were depleted by strong anion-exchange chromatography. The myoglobin fraction was digested and injected onto a 60 mm x 0.2 mm i.d. monolithic capillary column for quantitation of selected peptides upon mass spectrometric detection. The addition of known amounts of myoglobin to the serum sample was utilized for calibration, and horse myoglobin was added as an internal standard to improve reproducibility. Calibration graphs were linear and facilitated the reproducible and accurate determination of the myoglobin amount present in serum. Manual data evaluation using integrated peak areas and an automated multistage algorithm fitting two-dimensional models of peptide elution profiles and isotope patterns to the mass spectrometric raw data were compared. When the automated method was applied, a myoglobin concentration of 460 pg/microL serum was determined with a maximum relative deviation from the theoretical value of 10.1% and a maximum relative standard deviation of 13.4%.},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=16457608&retmode=ref&cmd=prlinks},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2006/Mayr/J%20Proteome%20Res%202006%20Mayr.pdf},
file = {{J Proteome Res 2006 Mayr.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2006/Mayr/J Proteome Res 2006 Mayr.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1021/pr050344u}}
}

@article{Althaus:2006wq,
author = {Althaus, Ernst and Caprara, Alberto and Lenhof, Hans-Peter and Reinert, Knut},
title = {{A branch-and-cut algorithm for multiple sequence alignment}},
journal = {Mathematical Programming},
year = {2006},
read = {Yes},
rating = {0},
date-added = {2008-03-24T20:04:25GMT},
date-modified = {2015-07-12T09:51:09GMT},
abstract = {Page 1. Digital Object Identifier (DOI) 10.1007/s10107-005-0659-3 Math. Program., Ser. B 105, 387{\textendash}425 (2006) Ernst Althaus {\textperiodcentered} Alberto Caprara {\textperiodcentered} Hans-Peter Lenhof {\textperiodcentered} Knut Reinert A branch-and-cut algorithm for multiple sequence alignment },
url = {http://www.springerlink.com/index/773603M7M1V5HU14.pdf},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2006/Althaus/Math%20Program%202006%20Althaus.pdf},
file = {{Math Program 2006 Althaus.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2006/Althaus/Math Program 2006 Althaus.pdf:application/pdf}},
uri = {\url{papers3://publication/uuid/01DA765D-28B3-4495-83B7-AE48B693127D}}
}

@article{Reinert1997,
author = {Althaus, Ernst and Caprara, Alberto and Lenhof, H P and Reinert, Knut},
title = {{A branch-and-cut algorithm for multiple sequence alignment}},
journal = {Mathematical Programming},
year = {2006},
volume = {105},
number = {2-3},
pages = {387--425},
doi = {10.1007/s10107-005-0659-3},
language = {English},
rating = {0},
date-added = {2013-09-04T14:04:14GMT},
date-modified = {2015-12-10T19:24:45GMT},
abstract = {Abstract We consider a branch-and-cut approach for solving the multiple sequence alignment problem, which is a central problem in computational biology. We propose a general model for this problem in which arbitrary gap costs are allowed. An interesting ...},
url = {http://link.springer.com/10.1007/s10107-005-0659-3},
uri = {\url{papers3://publication/doi/10.1007/s10107-005-0659-3}}
}

@article{Lange:2006vv,
author = {Lange, Eva and Gr{\"o}pl, Clemens and Reinert, Knut and Kohlbacher, Oliver and Hildebrandt, Andreas},
title = {{High-accuracy peak picking of proteomics data using wavelet techniques.}},
journal = {Pacific Symposium on Biocomputing Pacific Symposium on Biocomputing},
year = {2006},
pages = {243--254},
affiliation = {Institute of Computer Science, Free University of Berlin Takustr. 9, 14195 Berlin, Germany. lange@inf.fu-berlin.de},
pmid = {17094243},
language = {English},
rating = {2},
date-added = {2008-03-27T07:42:43GMT},
date-modified = {2015-11-06T12:10:09GMT},
abstract = {A new peak picking algorithm for the analysis of mass spectrometric (MS) data is presented. It is independent of the underlying machine or ionization method, and is able to resolve highly convoluted and asymmetric signals. The method uses the multiscale nature of spectrometric data by first detecting the mass peaks in the wavelet-transformed signal before a given asymmetric peak function is fitted to the raw data. In an optional third stage, the resulting fit can be further improved using techniques from nonlinear optimization. In contrast to currently established techniques (e.g. SNAP, Apex) our algorithm is able to separate overlapping peaks of multiply charged peptides in ESI-MS data of low resolution. Its improved accuracy with respect to peak positions makes it a valuable preprocessing method for MS-based identification and quantification experiments. The method has been validated on a number of different annotated test cases, where it compares favorably in both runtime and accuracy with currently established techniques. An implementation of the algorithm is freely available in our open source framework OpenMS.},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=17094243&retmode=ref&cmd=prlinks},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2006/Lange/Pacific%20Symposium%20on%20Biocomputing%20Pacific%20Symposium%20on%20Biocomputing%202006%20Lange.pdf},
file = {{Pacific Symposium on Biocomputing Pacific Symposium on Biocomputing 2006 Lange.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2006/Lange/Pacific Symposium on Biocomputing Pacific Symposium on Biocomputing 2006 Lange.pdf:application/pdf}},
uri = {\url{papers3://publication/uuid/75CD0ADE-B786-4821-BAB7-2780B6B86B57}}
}

@article{Mayr:2006te,
author = {Mayr, B M and Kohlbacher, Oliver and Reinert, Knut},
title = {{Absolute myoglobin quantitation in serum by combining two-dimensional liquid chromatography-electrospray ionization mass spectrometry and novel data analysis {\ldots}}},
journal = {Journal of proteome {\ldots}},
year = {2006},
rating = {0},
date-added = {2015-09-08T22:50:10GMT},
date-modified = {2015-11-26T15:38:49GMT},
abstract = {Myoglobin is a sensitive marker of myocardial infarction. To measure its concentration directly in human serum, a combination of two-dimensional liquid chromatography and electrospray ionization mass spectrometry was elaborated as analytical protocol. In ... 
},
url = {http://pubs.acs.org/doi/abs/10.1021/pr050344u},
uri = {\url{papers3://publication/uuid/00D0F208-5C0E-4CA1-B4FC-1834982FF9FB}}
}

@article{Bafna:2006tx,
author = {Bafna, Vineet and Reinert, Knut},
title = {{Mass Spectrometry and Computational Proteomics}},
journal = {Encyclopedia of Genetics},
year = {2006},
read = {Yes},
rating = {0},
date-added = {2008-03-24T20:08:00GMT},
date-modified = {2015-11-06T12:10:07GMT},
url = {http://www-cse.ucsd.edu/users/vbafna/pub/wileyeastern.pdf},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2006/Bafna/Encyclopedia%20of%20Genetics%202006%20Bafna.pdf},
file = {{Encyclopedia of Genetics 2006 Bafna.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2006/Bafna/Encyclopedia of Genetics 2006 Bafna.pdf:application/pdf}},
uri = {\url{papers3://publication/uuid/AD263B62-A001-40FE-946D-695CFBA5432D}}
}

@article{Wolski:2006kx,
author = {Wolski, Witold E and Farrow, Malcolm and Emde, A and Lehrach, Hans and Lalowski, Maciej and Reinert, Knut},
title = {{Analytical model of peptide mass cluster centres with applications.}},
journal = {Proteome science},
year = {2006},
volume = {4},
pages = {18},
affiliation = {School of Mathematics and Statistics, Merz Court, University of Newcastle upon Tyne, NE1 7RU, UK. w.e.wolski@ncl.ac.uk},
doi = {10.1186/1477-5956-4-18},
pmid = {16995952},
pmcid = {PMC1617084},
language = {English},
rating = {0},
date-added = {2008-03-10T22:10:38GMT},
date-modified = {2015-11-06T12:10:06GMT},
abstract = {BACKGROUND:The elemental composition of peptides results in formation of distinct, equidistantly spaced clusters across the mass range. The property of peptide mass clustering is used to calibrate peptide mass lists, to identify and remove non-peptide peaks and for data reduction.

RESULTS:We developed an analytical model of the peptide mass cluster centres. Inputs to the model included, the amino acid frequencies in the sequence database, the average length of the proteins in the database, the cleavage specificity of the proteolytic enzyme used and the cleavage probability. We examined the accuracy of our model by comparing it with the model based on an in silico sequence database digest. To identify the crucial parameters we analysed how the cluster centre location depends on the inputs. The distance to the nearest cluster was used to calibrate mass spectrometric peptide peak-lists and to identify non-peptide peaks.

CONCLUSION:The model introduced here enables us to predict the location of the peptide mass cluster centres. It explains how the location of the cluster centres depends on the input parameters. Fast and efficient calibration and filtering of non-peptide peaks is achieved by a distance measure suggested by Wool and Smilansky.},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=16995952&retmode=ref&cmd=prlinks},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2006/Wolski/Proteome%20Sci%202006%20Wolski.pdf},
file = {{Proteome Sci 2006 Wolski.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2006/Wolski/Proteome Sci 2006 Wolski.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1186/1477-5956-4-18}}
}

@article{Wolski:2005fv,
author = {Wolski, Witold E and Lalowski, Maciej and Martus, Peter and Herwig, Ralf and Giavalisco, Patrick and Gobom, Johan and Sickmann, Albert and Lehrach, Hans and Reinert, Knut},
title = {{Transformation and other factors of the peptide mass spectrometry pairwise peak-list comparison process.}},
journal = {BMC Bioinformatics},
year = {2005},
volume = {6},
pages = {285},
affiliation = {Max Planck Institute for Molecular Genetics, Ihnestrasse 63-73, D-14195 Berlin, Germany. w.e.wolski@ncl.ac.uk},
doi = {10.1186/1471-2105-6-285},
pmid = {16318636},
pmcid = {PMC1343595},
language = {English},
read = {Yes},
rating = {0},
date-added = {2008-10-31T11:35:08GMT},
date-modified = {2015-11-06T12:10:11GMT},
abstract = {BACKGROUND:Biological Mass Spectrometry is used to analyse peptides and proteins. A mass spectrum generates a list of measured mass to charge ratios and intensities of ionised peptides, which is called a peak-list. In order to classify the underlying amino acid sequence, the acquired spectra are usually compared with synthetic ones. Development of suitable methods of direct peak-list comparison may be advantageous for many applications.

RESULTS:The pairwise peak-list comparison is a multistage process composed of matching of peaks embedded in two peak-lists, normalisation, scaling of peak intensities and dissimilarity measures. In our analysis, we focused on binary and intensity based measures. We have modified the measures in order to comprise the mass spectrometry specific properties of mass measurement accuracy and non-matching peaks. We compared the labelling of peak-list pairs, obtained using different factors of the pairwise peak-list comparison, as being the same or different to those determined by sequence database searches. In order to elucidate how these factors influence the peak-list comparison we adopted an analysis of variance type method with the partial area under the ROC curve as a dependent variable.

CONCLUSION:The analysis of variance provides insight into the relevance of various factors influencing the outcome of the pairwise peak-list comparison. For large MS/MS and PMF data sets the outcome of ANOVA analysis was consistent, providing a strong indication that the results presented here might be valid for many various types of peptide mass measurements.},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=16318636&retmode=ref&cmd=prlinks},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2005/Wolski/BMC%20Bioinformatics%202005%20Wolski.pdf},
file = {{BMC Bioinformatics 2005 Wolski.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2005/Wolski/BMC Bioinformatics 2005 Wolski.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1186/1471-2105-6-285}}
}

@article{Bauer:2005vy,
author = {Bauer, M and Klau, Gunnar W and Reinert, Knut},
title = {{Multiple Structural RNA Alignment with Lagrangian Relaxation}},
journal = {Algorithms in Bioinformatics: 5th International Workshop},
year = {2005},
read = {Yes},
rating = {0},
date-added = {2008-03-10T22:17:13GMT},
date-modified = {2015-11-02T12:35:34GMT},
abstract = {Multiple Structural RNA Alignment with Lagrangian Relaxation Extended Abstract Markus Bauer 1'2, Gunnar W. Klau 3, and Knut Reinert 1 Institute of Computer Science, Free University of Berlin, Germany 2 International Max Planck },
url = {http://books.google.com/books?hl=en&lr=&ie=UTF-8&id=yZ7hSGG99pIC&oi=fnd&pg=PA303&dq=FoOaETE9GA4J:scholar.google.com/&ots=RuhODo3L7V&sig=GO3McCqo4vuch2QUIqxfhUAVKpI},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2005/Bauer/Algorithms%20in%20Bioinformatics%205th%20International%20Workshop%202005%20Bauer.pdf},
file = {{Algorithms in Bioinformatics 5th International Workshop 2005 Bauer.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2005/Bauer/Algorithms in Bioinformatics 5th International Workshop 2005 Bauer.pdf:application/pdf}},
uri = {\url{papers3://publication/uuid/52146754-DC79-4ACE-9469-DFDB29964582}}
}

@article{Gropl:2005vj,
author = {Gr{\"o}pl, Clemens and Lange, Eva and Reinert, Knut and Kohlbacher, Oliver and Sturm, Marc and Huber, Christian G and Mayr, Bettina M and Klein, Christoph L},
title = {{Algorithms for the automated absolute quantification of diagnostic markers in complex proteomics samples}},
year = {2005},
pages = {151--162},
publisher = {Springer},
isbn = {3540291040},
read = {Yes},
rating = {0},
date-added = {2013-06-24T07:41:17GMT},
date-modified = {2015-07-12T09:51:09GMT},
url = {http://link.springer.com/chapter/10.1007/11560500_14},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2005/Gr%C3%B6pl/2005%20Gr%C3%B6pl.pdf},
file = {{2005 Gröpl.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2005/Gröpl/2005 Gröpl.pdf:application/pdf;2005 Gröpl.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2005/Gröpl/2005 Gröpl.pdf:application/pdf}},
uri = {\url{papers3://publication/uuid/CBA9ECDD-B908-434F-8268-640AB591D115}}
}

@article{Wolski:2005es,
author = {Wolski, Witold E and Lalowski, Maciej and Jungblut, Peter and Reinert, Knut},
title = {{Calibration of mass spectrometric peptide mass fingerprint data without specific external or internal calibrants.}},
journal = {BMC Bioinformatics},
year = {2005},
volume = {6},
pages = {203},
affiliation = {Max Planck Institute for Molecular Genetics, Ihnestrasse 63-73, D-14195 Berlin, Germany. w.e.wolski@ncl.ac.uk},
doi = {10.1186/1471-2105-6-203},
pmid = {16102175},
pmcid = {PMC1199585},
language = {English},
rating = {0},
date-added = {2008-03-10T22:13:30GMT},
date-modified = {2015-11-06T12:10:06GMT},
abstract = {BACKGROUND:Peptide Mass Fingerprinting (PMF) is a widely used mass spectrometry (MS) method of analysis of proteins and peptides. It relies on the comparison between experimentally determined and theoretical mass spectra. The PMF process requires calibration, usually performed with external or internal calibrants of known molecular masses.

RESULTS:We have introduced two novel MS calibration methods. The first method utilises the local similarity of peptide maps generated after separation of complex protein samples by two-dimensional gel electrophoresis. It computes a multiple peak-list alignment of the data set using a modified Minimum Spanning Tree (MST) algorithm. The second method exploits the idea that hundreds of MS samples are measured in parallel on one sample support. It improves the calibration coefficients by applying a two-dimensional Thin Plate Splines (TPS) smoothing algorithm. We studied the novel calibration methods utilising data generated by three different MALDI-TOF-MS instruments. We demonstrate that a PMF data set can be calibrated without resorting to external or relying on widely occurring internal calibrants. The methods developed here were implemented in R and are part of the BioConductor package mscalib available from http://www.bioconductor.org.

CONCLUSION:The MST calibration algorithm is well suited to calibrate MS spectra of protein samples resulting from two-dimensional gel electrophoretic separation. The TPS based calibration algorithm might be used to correct systematic mass measurement errors observed for large MS sample supports. As compared to other methods, our combined MS spectra calibration strategy increases the peptide/protein identification rate by an additional 5-15%.},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=16102175&retmode=ref&cmd=prlinks},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2005/Wolski/BMC%20Bioinformatics%202005%20Wolski-2.pdf},
file = {{BMC Bioinformatics 2005 Wolski-2.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2005/Wolski/BMC Bioinformatics 2005 Wolski-2.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1186/1471-2105-6-203}}
}

@article{Bauer:2005tn,
author = {Bauer, M and Klau, Gunnar W and Reinert, Knut},
title = {{Fast and Accurate Structural RNA Alignment by Progressive Lagrangian Optimization}},
journal = {Computational Life Sciences: First International Symposium},
year = {2005},
read = {Yes},
rating = {0},
date-added = {2008-03-10T22:16:07GMT},
date-modified = {2015-11-02T12:35:04GMT},
abstract = {Fast and Accurate Structural RNA Alignment by Progressive Lagrangian Optimization* Markus Bauer 1-2, Gunnar W. Klau 3, and Knut Reinert 1 1 Algorithmic Bioinformatics Group, Institute of Computer Science, Free },
url = {http://dx.doi.org/10.1007/11560500_20},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2005/Bauer/Computational%20Life%20Sciences%20First%20International%20Symposium%202005%20Bauer.pdf},
file = {{Computational Life Sciences First International Symposium 2005 Bauer.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2005/Bauer/Computational Life Sciences First International Symposium 2005 Bauer.pdf:application/pdf}},
uri = {\url{papers3://publication/uuid/1D21F338-32AC-46D9-A75C-4E0ABCCDB0DB}}
}

@article{Klau:2004kb,
author = {Klau, Gunnar W and Rahmann, Sven and Schliep, Alexander and Vingron, Martin and Reinert, Knut},
title = {{Optimal robust non-unique probe selection using Integer Linear Programming.}},
journal = {Bioinformatics (Oxford, England)},
year = {2004},
volume = {20 Suppl 1},
pages = {i186--93},
month = aug,
affiliation = {Institute of Computer Graphics and Algorithms, Vienna University of Technology, Vienna, Austria.},
doi = {10.1093/bioinformatics/bth936},
pmid = {15262798},
language = {English},
read = {Yes},
rating = {0},
date-added = {2008-03-10T19:59:30GMT},
date-modified = {2015-11-06T12:10:06GMT},
abstract = {MOTIVATION:Besides their prevalent use for analyzing gene expression, microarrays are an efficient tool for biological, medical and industrial applications due to their ability to assess the presence or absence of biological agents, the targets, in a sample. Given a collection of genetic sequences of targets one faces the challenge of finding short oligonucleotides, the probes, which allow detection of targets in a sample. Each hybridization experiment determines whether the probe binds to its corresponding sequence in the target. Depending on the problem, the experiments are conducted using either unique or non-unique probes and usually assume that only one target is present in the sample. The problem at hand is to compute a design, i.e. a minimal set of probes that allows to infer the targets in the sample from the result of the hybridization experiment. If we allow to test for more than one target in the sample, the design of the probe set becomes difficult in the case of non-unique probes.

RESULTS:Building upon previous work on group testing for microarrays, we describe the first approach to select a minimal probe set for the case of non-unique probes in the presence of a small number of multiple targets in the sample. The approach is based on an ILP formulation and a branch-and-cut algorithm. Our preliminary implementation greatly reduces the number of probes needed while preserving the decoding capabilities.

AVAILABILITY:http://www.inf.fu-berlin.de/inst/ag-bio},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=15262798&retmode=ref&cmd=prlinks},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2004/Klau/Bioinformatics%202004%20Klau.pdf},
file = {{Bioinformatics 2004 Klau.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2004/Klau/Bioinformatics 2004 Klau.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1093/bioinformatics/bth936}}
}

@article{Istrail:2004dw,
author = {Istrail, Sorin and Sutton, Granger G and Florea, Liliana and Halpern, Aaron L and Mobarry, Clark M and Lippert, Ross and Walenz, Brian P and Shatkay, Hagit and Dew, I M and Miller, Jason R and Flanigan, Michael J and Edwards, N and Bolanos, R and Fasulo, D and Halldorsson, Bjarni V and Hannenhalli, Sridhar and Turner, Russell and Yooseph, Shibu and Lu, Fu and Nusskern, Deborah R and Shue, Bixiong Chris and Zheng, Xiangqun Holly and Zhong, Fei and Delcher, Arthur and Huson, Daniel H and Kravitz, Saul A and Mouchard, Laurent and Reinert, Knut and Remington, Karin A and Clark, A G and Waterman, Michael S and Eichler, Evan E and Adams, Mark D and Hunkapiller, Michael W and Myers, Eugene W and Venter, J Craig},
title = {{Whole-genome shotgun assembly and comparison of human genome assemblies.}},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
year = {2004},
volume = {101},
number = {7},
pages = {1916--1921},
month = feb,
publisher = {National Acad Sciences},
affiliation = {Applied Biosystems, 45 West Gude Drive, Rockville, MD 20850, USA.},
doi = {10.1073/pnas.0307971100},
pmid = {14769938},
pmcid = {PMC357027},
language = {English},
read = {Yes},
rating = {0},
date-added = {2008-03-24T10:39:19GMT},
date-modified = {2015-11-06T12:10:07GMT},
abstract = {We report a whole-genome shotgun assembly (called WGSA) of the human genome generated at Celera in 2001. The Celera-generated shotgun data set consisted of 27 million sequencing reads organized in pairs by virtue of end-sequencing 2-kbp, 10-kbp, and 50-kbp inserts from shotgun clone libraries. The quality-trimmed reads covered the genome 5.3 times, and the inserts from which pairs of reads were obtained covered the genome 39 times. With the nearly complete human DNA sequence [National Center for Biotechnology Information (NCBI) Build 34] now available, it is possible to directly assess the quality, accuracy, and completeness of WGSA and of the first reconstructions of the human genome reported in two landmark papers in February 2001 [Venter, J. C., Adams, M. D., Myers, E. W., Li, P. W., Mural, R. J., Sutton, G. G., Smith, H. O., Yandell, M., Evans, C. A., Holt, R. A., et al. (2001) Science 291, 1304-1351; International Human Genome Sequencing Consortium (2001) Nature 409, 860-921]. The analysis of WGSA shows 97% order and orientation agreement with NCBI Build 34, where most of the 3% of sequence out of order is due to scaffold placement problems as opposed to assembly errors within the scaffolds themselves. In addition, WGSA fills some of the remaining gaps in NCBI Build 34. The early genome sequences all covered about the same amount of the genome, but they did so in different ways. The Celera results provide more order and orientation, and the consortium sequence provides better coverage of exact and nearly exact repeats.},
url = {http://www.pnas.org/content/101/7/1916.full},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2004/Istrail/Proc%20Natl%20Acad%20Sci%20USA%202004%20Istrail.pdf},
file = {{Proc Natl Acad Sci USA 2004 Istrail.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2004/Istrail/Proc Natl Acad Sci USA 2004 Istrail.pdf:application/pdf;Proc Natl Acad Sci USA 2004 Istrail.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2004/Istrail/Proc Natl Acad Sci USA 2004 Istrail.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1073/pnas.0307971100}}
}

@article{Huson:2002kf,
author = {Huson, Daniel H and Reinert, Knut and Myers, Eugene W},
title = {{The greedy path-merging algorithm for contig scaffolding}},
journal = {Journal of the ACM (JACM},
year = {2002},
volume = {49},
number = {5},
month = sep,
doi = {10.1145/585265.585267},
rating = {0},
date-added = {2008-03-10T22:25:40GMT},
date-modified = {2015-11-06T12:10:06GMT},
abstract = {Given a collection of contigs and mate-pairs. The Contig Scaffolding Problem is to order and orientate the given contigs in a manner that is consistent with as many mate-pairs as possible. This paper describes an efficient heuristic called the ...},
url = {http://portal.acm.org/citation.cfm?id=585265.585267},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2002/Huson/Journal%20of%20the%20ACM%20(JACM%202002%20Huson.pdf},
file = {{Journal of the ACM (JACM 2002 Huson.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2002/Huson/Journal of the ACM (JACM 2002 Huson.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1145/585265.585267}}
}

@article{Bailey:2002jp,
author = {Bailey, Jeffrey A and Gu, Zhiping and Clark, Royden A and Reinert, Knut and Samonte, Rhea V and Schwartz, Stuart and Adams, Mark D and Myers, Eugene W and Li, Peter W and Eichler, Evan E},
title = {{Recent segmental duplications in the human genome.}},
journal = {Science (New York, NY)},
year = {2002},
volume = {297},
number = {5583},
pages = {1003--1007},
month = aug,
affiliation = {Department of Genetics, Center for Computational Genomics, and Center for Human Genetics, Case Western Reserve University School of Medicine and University Hospitals of Cleveland, Cleveland, OH 44106, USA.},
doi = {10.1126/science.1072047},
pmid = {12169732},
language = {English},
rating = {0},
date-added = {2008-03-10T22:23:21GMT},
date-modified = {2015-11-06T12:10:06GMT},
abstract = {Primate-specific segmental duplications are considered important in human disease and evolution. The inability to distinguish between allelic and duplication sequence overlap has hampered their characterization as well as assembly and annotation of our genome. We developed a method whereby each public sequence is analyzed at the clone level for overrepresentation within a whole-genome shotgun sequence. This test has the ability to detect duplications larger than 15 kilobases irrespective of copy number, location, or high sequence similarity. We mapped 169 large regions flanked by highly similar duplications. Twenty-four of these hot spots of genomic instability have been associated with genetic disease. Our analysis indicates a highly nonrandom chromosomal and genic distribution of recent segmental duplications, with a likely role in expanding protein diversity.},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=12169732&retmode=ref&cmd=prlinks},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2002/Bailey/Science%202002%20Bailey.pdf},
file = {{Science 2002 Bailey.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2002/Bailey/Science 2002 Bailey.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1126/science.1072047}}
}

@article{Mural:2002ex,
author = {Mural, Richard J and Adams, Mark D and Myers, Eugene W and Smith, Hamilton O and Miklos, George L Gabor and Wides, Ron and Halpern, Aaron and Li, Peter W and Sutton, Granger G and Nadeau, Joe and Salzberg, S and Holt, Robert A and Kodira, Chinnappa D and Lu, Fu and Chen, Lin and Deng, Zuoming and Evangelista, Carlos and Gan, Weiniu and Heiman, Thomas J and Li, Jiayin and Li, Zhenya and Merkulov, Gennady V and Milshina, Natalia V and Naik, Ashwinikumar K and Qi, Rong and Shue, Bixiong Chris and Wang, Aihui and Wang, Jian and Wang, Xin and Yan, Xianghe and Ye, Jane and Yooseph, Shibu and Zhao, Qi and Zheng, Liansheng and Zhu, Shiaoping C and Biddick, Kendra and Bolanos, R and Delcher, Arthur and Dew, I M and Fasulo, D and Flanigan, Michael J and Huson, Daniel H and Kravitz, Saul A and Miller, Jason R and Mobarry, Clark M and Reinert, Knut and Remington, Karin A and Zhang, Qing and Zheng, Xiangqun Holly and Nusskern, Deborah R and Lai, Zhongwu and Lei, Yiding and Zhong, Wenyan and Yao, Alison and Guan, Ping and Ji, Rui-Ru and Gu, Zhiping and Wang, Zhen-Yuan and Zhong, Fei and Xiao, Chunlin and Chiang, Chia-Chien and Yandell, Mark D and Wortman, Jennifer R and Amanatides, Peter and Hladun, Suzanne L and Pratts, Eric C and Johnson, Jeffery E and Dodson, Kristina and Woodford, Kerry J and Evans, C A and Gropman, Barry and Rusch, Douglas B and Venter, Eli and Wang, Mei and Smith, Thomas J and Houck, Jarrett T and Tompkins, Donald E and Haynes, Charles and Jacob, Debbie and Chin, Soo H and Allen, David R and Dahlke, Carl E and Sanders, Robert and Li, Kelvin and Liu, Xiangjun and Levitsky, Alexander A and Majoros, William H and Chen, Q and Xia, Ashley C and Lopez, John R and Donnelly, Michael and Newman, Matthew H and Glodek, Anna and Kraft, Cheryl L and Nodell, Marc and Ali, Feroze and An, Huijin and Baldwin-Pitts, Danita and Beeson, Karen and Cai, Shuang and Carnes, Mark and Carver, Amy and Caulk, Parris and Center, A and Chen, Yen-Hui and Cheng, Ming-Lai and Coyne, My and Crowder, Michelle and Danaher, Steven and Davenport, Lionel B and Desilets, Raymond and Dietz, Susanne and Doup, Lisa and Dullaghan, Patrick and Ferriera, Steven and Fosler, Carl R and Gire, Harold C and Gluecksmann, Andres and Gocayne, Jeannine D and Gray, Jonathan and Hart, Brit and Haynes, Jason and Hoover, Jeffery and Howland, Tim and Ibegwam, Chinyere and Jalali, Mena and Johns, David and Kline, Leslie and Ma, Daniel S and MacCawley, Steven and Magoon, Anand and Mann, Felecia and May, David and McIntosh, Tina C and Mehta, Somil and Moy, Linda and Moy, Mee C and Murphy, Brian J and Murphy, Sean D and Nelson, Keith A and Nuri, Zubeda and Parker, Kimberly A and Prudhomme, Alexandre C and Puri, Vinita N and Qureshi, Hina and Raley, John C and Reardon, Matthew S and Regier, Megan A and Rogers, Yu-Hui C and Romblad, Deanna L and Schutz, Jakob and Scott, John L and Scott, Richard and Sitter, Cynthia D and Smallwood, Michella and Sprague, Arlan C and Stewart, Erin and Strong, Renee V and Suh, Ellen and Sylvester, Karena and Thomas, Reginald and Tint, Ni Ni and Tsonis, Christopher and Wang, Gary and Wang, George and Williams, Monica S and Williams, Sherita M and Windsor, Sandra M and Wolfe, Keriellen and Wu, Mitchell M and Zaveri, Jayshree S and Chaturvedi, Kabir and Gabrielian, Andrei E and Ke, Zhaoxi and Sun, Jingtao and Subramanian, G Mani and Venter, J Craig and Pfannkoch, Cynthia M and Barnstead, Mary and Stephenson, Lisa D},
title = {{A comparison of whole-genome shotgun-derived mouse chromosome 16 and the human genome.}},
journal = {Science (New York, NY)},
year = {2002},
volume = {296},
number = {5573},
pages = {1661--1671},
month = may,
publisher = {American Association for the Advancement of Science},
affiliation = {Celera Genomics, 45 West Gude Drive, Rockville, MD 20850, USA. richard.mural@celera.com},
doi = {10.1126/science.1069193},
pmid = {12040188},
language = {English},
read = {Yes},
rating = {0},
date-added = {2008-03-24T20:00:04GMT},
date-modified = {2015-11-06T12:10:07GMT},
abstract = {The high degree of similarity between the mouse and human genomes is demonstrated through analysis of the sequence of mouse chromosome 16 (Mmu 16), which was obtained as part of a whole-genome shotgun assembly of the mouse genome. The mouse genome is about 10% smaller than the human genome, owing to a lower repetitive DNA content. Comparison of the structure and protein-coding potential of Mmu 16 with that of the homologous segments of the human genome identifies regions of conserved synteny with human chromosomes (Hsa) 3, 8, 12, 16, 21, and 22. Gene content and order are highly conserved between Mmu 16 and the syntenic blocks of the human genome. Of the 731 predicted genes on Mmu 16, 509 align with orthologs on the corresponding portions of the human genome, 44 are likely paralogous to these genes, and 164 genes have homologs elsewhere in the human genome; there are 14 genes for which we could find no human counterpart.},
url = {http://www.sciencemag.org/content/296/5573/1661.full},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2002/Mural/Science%202002%20Mural.pdf},
file = {{Science 2002 Mural.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2002/Mural/Science 2002 Mural.pdf:application/pdf;Science 2002 Mural.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2002/Mural/Science 2002 Mural.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1126/science.1069193}}
}

@inproceedings{Halpern:2002vi,
author = {Halpern, A and DH Huson, Daniel H and Reinert, Knut},
title = {{Segment Match Refinement and Applications}},
booktitle = {LECTURE NOTES IN COMPUTER SCIENCE},
year = {2002},
read = {Yes},
rating = {0},
date-added = {2008-10-31T12:02:38GMT},
date-modified = {2015-11-06T12:10:11GMT},
abstract = {[PS]},
url = {http://www.springerlink.com/index/JT6VL8AXWFV974D0.pdf},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2002/Halpern/LECTURE%20NOTES%20IN%20COMPUTER%20SCIENCE%202002%20Halpern.pdf},
file = {{LECTURE NOTES IN COMPUTER SCIENCE 2002 Halpern.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2002/Halpern/LECTURE NOTES IN COMPUTER SCIENCE 2002 Halpern.pdf:application/pdf}},
uri = {\url{papers3://publication/uuid/8FAD8AA9-D016-4BD7-907B-DBF34AAAD2C4}}
}

@article{Bailey:2002um,
author = {Bailey, J A and Gu, Z and Clark, R A and Reinert, Knut and Samonte, R V},
title = {{Recent segmental duplications in the human genome}},
journal = {Science (New York, NY)},
year = {2002},
rating = {0},
date-added = {2015-09-08T22:50:12GMT},
date-modified = {2015-11-26T15:38:49GMT},
abstract = {Abstract Primate-specific segmental duplications are considered important in human disease and evolution. The inability to distinguish between allelic and duplication sequence overlap has hampered their characterization as well as assembly and annotation of our ... 
},
url = {http://www.sciencemag.org/content/297/5583/1003.short},
uri = {\url{papers3://publication/uuid/4B19075B-D966-4517-9770-425CA1FBBB5A}}
}

@article{Venter:2001fqa,
author = {Venter, J Craig and Adams, Mark D and Myers, Eugene W and Li, P W and Mural, R J and Sutton, Granger G and Smith, Hamilton O and Yandell, Mark D and Evans, C A and Holt, R A and Gocayne, J D and Amanatides, Peter and Ballew, R M and Huson, D H and Wortman, Jennifer R and Zhang, Q and Kodira, C D and Zheng, X H and Chen, L and Skupski, Marian and Subramanian, G Mani and Thomas, P D and Zhang, J and Gabor Miklos, G L and Nelson, C and Broder, S and Clark, A G and Nadeau, J and McKusick, V A and Zinder, N and Levine, A J and Roberts, R J and Simon, Mel and Slayman, C and Hunkapiller, M and Bolanos, R and Delcher, Arthur and Dew, I M and Fasulo, D and Flanigan, M and Florea, L and Halpern, A and Hannenhalli, S and Kravitz, S and Levy, S and Mobarry, C and Reinert, Knut and Remington, K and Abu-Threideh, Jane and Beasley, Ellen and Biddick, Kendra and Bonazzi, V and Brandon, R and Cargill, Michele and Chandramouliswaran, Ishwar and Charlab, R and Chaturvedi, Kabir and Deng, Zuoming and Di Francesco, V and Dunn, Patrick and Eilbeck, Karen and Evangelista, C and Gabrielian, A E and Gan, W and Ge, W and Gong, F and Gu, Z and Guan, P and Heiman, T J and Higgins, Maureen E and Ji, R R and Ke, Z and Ketchum, K A and Lai, Z and Lei, Y and Li, Z and Li, J and Liang, Y and Lin, X and Lu, F and Merkulov, G V and Milshina, N and Moore, H M and Naik, A K and Narayan, V A and Neelam, B and Nusskern, D and Rusch, D B and Salzberg, S and Shao, W and Shue, Bixiong Chris and Sun, J and Wang, Z and Wang, AH H and Wang, X and Wang, J and Wei, M H and Wides, R and Xiao, C and Yan, C and Yao, Alison and Ye, J and Zhan, M and Zhang, W and Zhang, H and Zhao, Q and Zheng, L and Zhong, F and Zhong, W and Zhu, S and Zhao, S and Gilbert, D and Baumhueter, Suzanna and Spier, G and Carter, Christine and Cravchik, A and Woodage, T and Ali, Feroze and An, Huijin and Awe, A and Baldwin, D and Baden, Holly and Barnstead, Mary and Barrow, I and Beeson, Karen and Busam, Dana and Carver, Amy and Center, A and Cheng, Ming-Lai and Curry, Liz and Danaher, S and Davenport, L and Desilets, Raymond and Dietz, Susanne and Dodson, K and Doup, Lisa and Ferriera, S and Garg, N and Gluecksmann, A and Hart, B and Haynes, J and Haynes, C and Heiner, C and Hladun, S and Hostin, D and Houck, J and Howland, T and Ibegwam, C and Johnson, J and Kalush, Francis and Kline, L and Koduru, S and Love, A and Mann, F and May, D and McCawley, S and McIntosh, T and McMullen, I and Moy, M and Moy, L and Murphy, B and Nelson, K and Pfannkoch, C and Pratts, E and Puri, V and Qureshi, H and Reardon, M and Rodriguez, Robert and Rogers, Y H and Romblad, Deanna L and Ruhfel, B and Scott, R and Sitter, Cynthia D and Smallwood, Michella and Stewart, E and Strong, R and Suh, E and Thomas, R and Tint, N N and Tse, S and Vech, C and Wang, G and Wetter, J and Williams, S and Williams, Monica S and Windsor, S and Winn-Deen, E and Wolfe, K and Zaveri, Jayshree S and Zaveri, K and Abril, Josep F and Guigo, Roderic and Campbell, Michael J and Sjolander, K V and Karlak, B and Kejariwal, A and Mi, H and Lazareva, B and Hatton, T and Narechania, A and Diemer, Karen and Muruganujan, A and Guo, N and Sato, S and Bafna, Vineet and Istrail, S and Lippert, R and Schwartz, Russell and Walenz, Brian P and Yooseph, Shibu and Allen, David R and Basu, Anand and Baxendale, James and Blick, Louis and Caminha, Marcelo and Carnes-Stine, John and Caulk, Parris and Chiang, Yen-Hui and Coyne, My and Dahlke, C and Mays, A and Dombroski, Maria and Donnelly, Michael and Ely, D and Esparham, S and Fosler, C and Gire, H and Glanowski, S and Glasser, K and Glodek, A and Gorokhov, M and Graham, K and Gropman, Barry and Harris, M and Heil, J and Henderson, S and Hoover, J and Jennings, D and Jordan, C and Jordan, J and Kasha, J and Kagan, L and Kraft, C and Levitsky, A and Lewis, M and Liu, X and Lopez, J and Ma, D and Majoros, W and McDaniel, J and Murphy, S and Newman, M and Nguyen, T and Nguyen, N and Nodell, M and Pan, S and Peck, J and Peterson, M and Rowe, W and Sanders, R and Scott, J and Simpson, Michael and Smith, T and Sprague, Arlan C and Stockwell, Timothy B and Turner, Russell and Venter, Eli and Wang, M and Wen, M and Wu, D and Wu, M and Xia, A and Zandieh, Ali and Zhu, X},
title = {{The sequence of the human genome.}},
journal = {Science (New York, NY)},
year = {2001},
volume = {291},
number = {5507},
pages = {1304--1351},
month = feb,
publisher = {American Association for the Advancement of Science},
affiliation = {Celera Genomics, 45 West Gude Drive, Rockville, MD 20850, USA. humangenome@celera.com},
doi = {10.1126/science.1058040},
pmid = {11181995},
language = {English},
read = {Yes},
rating = {0},
date-added = {2014-08-27T09:05:22GMT},
date-modified = {2015-11-22T18:57:48GMT},
abstract = {A 2.91-billion base pair (bp) consensus sequence of the euchromatic portion of the human genome was generated by the whole-genome shotgun sequencing method. The 14.8-billion bp DNA sequence was generated over 9 months from 27,271,853 high-quality sequence reads (5.11-fold coverage of the genome) from both ends of plasmid clones made from the DNA of five individuals. Two assembly strategies-a whole-genome assembly and a regional chromosome assembly-were used, each combining sequence data from Celera and the publicly funded genome effort. The public data were shredded into 550-bp segments to create a 2.9-fold coverage of those genome regions that had been sequenced, without including biases inherent in the cloning and assembly procedure used by the publicly funded group. This brought the effective coverage in the assemblies to eightfold, reducing the number and size of gaps in the final assembly over what would be obtained with 5.11-fold coverage. The two assembly strategies yielded very similar results that largely agree with independent mapping data. The assemblies effectively cover the euchromatic regions of the human chromosomes. More than 90% of the genome is in scaffold assemblies of 100,000 bp or more, and 25% of the genome is in scaffolds of 10 million bp or larger. Analysis of the genome sequence revealed 26,588 protein-encoding transcripts for which there was strong corroborating evidence and an additional approximately 12,000 computationally derived genes with mouse matches or other weak supporting evidence. Although gene-dense clusters are obvious, almost half the genes are dispersed in low G+C sequence separated by large tracts of apparently noncoding sequence. Only 1.1% of the genome is spanned by exons, whereas 24% is in introns, with 75% of the genome being intergenic DNA. Duplications of segmental blocks, ranging in size up to chromosomal lengths, are abundant throughout the genome and reveal a complex evolutionary history. Comparative genomic analysis indicates vertebrate expansions of genes associated with neuronal function, with tissue-specific developmental regulation, and with the hemostasis and immune systems. DNA sequence comparisons between the consensus sequence and publicly funded genome data provided locations of 2.1 million single-nucleotide polymorphisms (SNPs). A random pair of human haploid genomes differed at a rate of 1 bp per 1250 on average, but there was marked heterogeneity in the level of polymorphism across the genome. Less than 1% of all SNPs resulted in variation in proteins, but the task of determining which SNPs have functional consequences remains an open challenge.},
url = {http://www.sciencemag.org/content/291/5507/1304.full},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Files/43/43E25C24-52F4-4DE2-94F3-5B81807A284A.pdf},
file = {{43E25C24-52F4-4DE2-94F3-5B81807A284A.pdf:/Users/reinert/Dropbox/Library.papers3/Files/43/43E25C24-52F4-4DE2-94F3-5B81807A284A.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1126/science.1058040}}
}

@inproceedings{Turner:2001ic,
author = {Turner, R J and Chaturvedi, Kabir and Edwards, N J and Fasulo, D and Halpern, A L and Huson, D H and Kohlbacher, Oliver and Miller, J R and Reinert, Knut and Remington, K A and Schwartz, Russell and Walenz, Brian P and Yooseph, Shibu and Istrail, S},
title = {{Visualization challenges for a new cyber-pharmaceutical computing paradigm}},
booktitle = {IEEE 2001 Symposium on Parallel and Large-Data Visualization and Graphics},
year = {2001},
pages = {7--145},
publisher = {IEEE},
doi = {10.1109/PVGS.2001.964398},
isbn = {0-7803-7223-9},
rating = {0},
date-added = {2015-09-08T22:50:13GMT},
date-modified = {2015-11-26T15:38:49GMT},
abstract = {Celera has encountered a number of visualization problems in the course of developing tools for bioinformatics research, applying them to our data generation efforts, and making that data available to our customers. This paper presents several examples from Celera's experience. In the area of genomics, challenging visualization problems have come up in assembling genomes, studying variations between individuals, and comparing different genomes to one another. The emerging area of proteomics has created new visualization challenges in interpreting protein expression data, studying protein regulatory networks, and examining protein structure. These examples illustrate how the field of bioinformatics is posing new challenges concerning the communication of data that are often very different from those that have heretofore dominated scientific computing. Addressing the level of detail, the degree of complexity, and the interdisciplinary barriers that characterize bioinformatic problems can be expected to be a sizable but rewarding task for the field of scientific visualization},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=964398},
uri = {\url{papers3://publication/doi/10.1109/PVGS.2001.964398}}
}

@article{DHHuson:2001ud,
author = {DH Huson, Daniel H and Kohlbacher, Oliver and Miller, J and Reinert, Knut},
title = {{Visualization challenges for a new cyberpharmaceutical computing paradigm}},
journal = {Proceedings of the IEEE 2001 symposium on parallel {\ldots}},
year = {2001},
rating = {0},
date-added = {2009-08-14T14:03:17GMT},
date-modified = {2015-11-06T12:10:13GMT},
abstract = { In Figure 8 we show a  of (Celera{\textquoteright}s  of) the  The matches where computed  BLAST with subsequent elimination of non- unique },
url = {http://portal.acm.org/citation.cfm?id=502127},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2001/DH%20Huson/Proceedings%20of%20the%20IEEE%202001%20symposium%20on%20parallel%20%E2%80%A6%202001%20DH%20Huson.pdf},
file = {{Proceedings of the IEEE 2001 symposium on parallel … 2001 DH Huson.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2001/DH Huson/Proceedings of the IEEE 2001 symposium on parallel … 2001 DH Huson.pdf:application/pdf}},
uri = {\url{papers3://publication/uuid/1639CE43-0EC8-4F55-9D25-6C7936DAD24E}}
}

@article{Huson:2001ul,
author = {Huson, D H and Reinert, Knut and Kravitz, S A and Remington, K A and Delcher, Arthur and Dew, I M and Flanigan, M and Halpern, A L and Lai, Z and Mobarry, C M and Sutton, Granger G and Myers, Eugene W},
title = {{Design of a compartmentalized shotgun assembler for the human genome.}},
journal = {Bioinformatics (Oxford, England)},
year = {2001},
volume = {17 Suppl 1},
pages = {S132--9},
affiliation = {Informatics Research, Celera Genomics, 45 West Gude Drive, Rockville 20850, USA.},
pmid = {11473002},
language = {English},
rating = {0},
date-added = {2008-03-10T22:28:43GMT},
date-modified = {2015-11-06T12:10:06GMT},
abstract = {Two different strategies for determining the human genome are currently being pursued: one is the "clone-by-clone" approach, employed by the publicly funded project, and the other is the "whole genome shotgun assembler" approach, favored by researchers at Celera Genomics. An interim strategy employed at Celera, called compartmentalized shotgun assembly, makes use of preliminary data produced by both approaches. In this paper we describe the design, implementation and operation of the "compartmentalized shotgun assembler".},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=11473002&retmode=ref&cmd=prlinks},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2001/Huson/Bioinformatics%202001%20Huson.pdf},
file = {{Bioinformatics 2001 Huson.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2001/Huson/Bioinformatics 2001 Huson.pdf:application/pdf}},
uri = {\url{papers3://publication/uuid/A4DB2664-A08F-4351-9B0B-E65AD0CAE568}}
}

@inproceedings{Halpern:2001wa,
author = {Halpern, A and Lai, Z and Myers, Eugene W and Reinert, Knut},
title = {{Comparing assemblies using fragments and mate-pairs}},
booktitle = {LECTURE NOTES IN COMPUTER SCIENCE},
year = {2001},
read = {Yes},
rating = {0},
date-added = {2009-08-14T14:05:00GMT},
date-modified = {2015-11-06T12:10:13GMT},
abstract = {Page 1.     and - Daniel H. , Aaron L. Halpern, Zhongwu Lai, Eugene W. Myers, Knut , and Granger G. Sutton },
url = {http://www.springerlink.com/index/U7PH04FL67DBHL09.pdf},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2001/Halpern/LECTURE%20NOTES%20IN%20COMPUTER%20SCIENCE%202001%20Halpern.pdf},
file = {{LECTURE NOTES IN COMPUTER SCIENCE 2001 Halpern.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2001/Halpern/LECTURE NOTES IN COMPUTER SCIENCE 2001 Halpern.pdf:application/pdf}},
uri = {\url{papers3://publication/uuid/4D8A4331-FE5A-4F50-8483-41E2468B3DF5}}
}

@article{Reinert:2000wp,
author = {Reinert, Knut and Stoye, Jens and Will, T},
title = {{An iterative method for faster sum-of-pairs multiple sequence alignment.}},
journal = {Bioinformatics (Oxford, England)},
year = {2000},
volume = {16},
number = {9},
pages = {808--814},
month = sep,
affiliation = {Celera Genomics, Informatics Research, 45 West Gude Drive, Rockville, MD 20850, USA.},
pmid = {11108703},
language = {English},
rating = {0},
date-added = {2013-09-04T14:04:09GMT},
date-modified = {2015-11-04T21:22:17GMT},
abstract = {MOTIVATION:Multiple sequence alignment is an important tool in computational biology. In order to solve the task of computing multiple alignments in affordable time, the most commonly used multiple alignment methods have to use heuristics. Nevertheless, the computation of optimal multiple alignments is important in its own right, and it provides a means of evaluating heuristic approaches or serves as a subprocedure of heuristic alignment methods.

RESULTS:We present an algorithm that uses the divide-and-conquer alignment approach together with recent results on search space reduction to speed up the computation of multiple sequence alignments. The method is adaptive in that depending on the time one wants to spend on the alignment, a better, up to optimal alignment can be obtained. To speed up the computation in the optimal alignment step, we apply the alpha(*) algorithm which leads to a procedure provably more efficient than previous exact algorithms. We also describe our implementation of the algorithm and present results showing the effectiveness and limitations of the procedure.},
url = {http://bioinformatics.oxfordjournals.org/cgi/reprint/16/9/808},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2000/Reinert/Bioinformatics%202000%20Reinert.pdf},
file = {{Bioinformatics 2000 Reinert.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2000/Reinert/Bioinformatics 2000 Reinert.pdf:application/pdf}},
uri = {\url{papers3://publication/uuid/C9CA9FF1-2CD4-48AD-89D2-5CA8DA493284}}
}

@article{Kececioglu:2000bw,
author = {Kececioglu, John D and Lenhof, Hans-Peter and Mehlhorn, Kurt and Mutzel, Petra and Reinert, Knut and Vingron, Martin},
title = {{A polyhedral approach to sequence alignment problems}},
journal = {Discrete Applied Mathematics},
year = {2000},
volume = {104},
number = {1-3},
pages = {143--186},
month = aug,
doi = {10.1016/S0166-218X(00)00194-3},
language = {English},
rating = {0},
date-added = {2015-09-08T22:50:15GMT},
date-modified = {2015-11-26T15:38:49GMT},
abstract = {We study two new problems in sequence alignment both from a practical and a theoretical view, using tools from combinatorial optimization to develop branch-and-cut algorithms. The generalized maximum trace formulation captures several forms of multiple sequence ... 
},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0166218X00001943},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Files/9A/9A15B8CF-E1C0-40C4-92F4-BCB11CD90BBC},
file = {{9A15B8CF-E1C0-40C4-92F4-BCB11CD90BBC:/Users/reinert/Dropbox/Library.papers3/Files/9A/9A15B8CF-E1C0-40C4-92F4-BCB11CD90BBC:application/pdf;9A15B8CF-E1C0-40C4-92F4-BCB11CD90BBC:/Users/reinert/Dropbox/Library.papers3/Files/9A/9A15B8CF-E1C0-40C4-92F4-BCB11CD90BBC:application/pdf}},
uri = {\url{papers3://publication/doi/10.1016/S0166-218X(00)00194-3}}
}

@article{Myers:2000wk,
author = {Brandon, R and Myers, Eugene W and Sutton, Granger G and Delcher, Arthur and Dew, I M and Fasulo, D and Flanigan, Michael J and Kravitz, S A and Mobarry, C M and Reinert, Knut and Remington, K A and Anson, Eric L and Bolanos, R and Chou, H H and Jordan, C M and Halpern, A L and Lonardi, S and Beasley, Ellen and Chen, L and Dunn, Patrick and Lai, Z and Liang, Y and Nusskern, D R and Zhan, M and Zhang, Q and Zheng, X H and Rubin, G M and Adams, Mark D and Venter, J Craig},
title = {{A whole-genome assembly of Drosophila}},
journal = {Science (New York, NY)},
year = {2000},
volume = {287},
number = {5461},
pages = {2196--2204},
month = mar,
affiliation = {Celera Genomics, Inc., 45 West Gude Drive, Rockville, MD 20850, USA. Gene.Myers@celera.com},
pmid = {10731133},
language = {eng},
read = {Yes},
rating = {0},
date-added = {2008-10-31T11:55:49GMT},
date-modified = {2015-11-06T12:10:11GMT},
abstract = {We report on the quality of a whole-genome assembly of Drosophila melanogaster and the nature of the computer algorithms that accomplished it. Three independent external data sources essentially agree with and support the assembly's sequence and ordering of contigs across the euchromatic portion of the genome. In addition, there are isolated contigs that we believe represent nonrepetitive pockets within the heterochromatin of the centromeres. Comparison with a previously sequenced 2.9- megabase region indicates that sequencing accuracy within nonrepetitive segments is greater than 99. 99% without manual curation. As such, this initial reconstruction of the Drosophila sequence should be of substantial value to the scientific community.},
url = {http://www.sciencemag.org/cgi/content/full/287/5461/2196},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2000/Brandon/Science%202000%20Brandon.pdf},
file = {{Science 2000 Brandon.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2000/Brandon/Science 2000 Brandon.pdf:application/pdf}},
uri = {\url{papers3://publication/uuid/1509AD80-BCC0-47D5-8544-63BA09416F01}}
}

@article{Adams:2000tj,
author = {Adams, Mark D and Brandon, R and Celniker, S E and Holt, Robert A and Evans, C A and Gocayne, J D and Amanatides, Peter and Scherer, S E and Li, P W and Hoskins, R A and Galle, R F and George, R A and Lewis, S E and Richards, S and Ashburner, M and Henderson, S N and Sutton, Granger G and Wortman, Jennifer R and Yandell, Mark D and Zhang, Q and Chen, L and Rogers, Y H and Blazej, R G and Champe, M and Pfeiffer, B D and Wan, K H and Doyle, C and Baxter, E G and Helt, G and Nelson, C R and Gabor Miklos, G L and Abril, Josep F and Agbayani, A and An, Huijin and Andrews-Pfannkoch, C and Baldwin, D and Ballew, R M and Basu, Anand and Baxendale, James and Bayraktaroglu, L and Beasley, Ellen and Beeson, Karen and Benos, P V and Berman, B P and Bhandari, D and Bolshakov, S and Borkova, D and Botchan, M R and Bouck, J and Brokstein, P and Brottier, P and Burtis, K C and Busam, Dana and Butler, H and Cadieu, E and Center, A and Chandra, I and Cherry, J M and Cawley, S and Dahlke, Carl E and Davenport, Lionel B and Davies, P and de Pablos, B and Delcher, Arthur and Deng, Zuoming and Mays, A D and Dew, I M and Dietz, Susanne and Dodson, Kristina and Doup, Lisa and Downes, M and Dugan-Rocha, S and Dunkov, B C and Dunn, Patrick and Durbin, K J and Evangelista, Carlos and Ferraz, C and Ferriera, S and Fleischmann, W and Fosler, C and Gabrielian, A E and Garg, N S and Gelbart, W M and Glasser, K and Glodek, A and Gong, F and Gorrell, J H and Gu, Z and Guan, P and Harris, M and Harris, N L and Harvey, D and Heiman, T J and Hernandez, J R and Houck, J and Hostin, D and Houston, K A and Howland, T J and Wei, M H and Ibegwam, C and Jalali, M and Kalush, Francis and Karpen, G H and Ke, Z and Kennison, J A and Ketchum, K A and Kimmel, B E and Kodira, C D and Kraft, C and Kravitz, S and Kulp, D and Lai, Z and Lasko, P and Lei, Y and Levitsky, A A and Li, J and Li, Z and Liang, Y and Lin, X and Liu, X and Mattei, B and McIntosh, T C and McLeod, M P and McPherson, D and Merkulov, G and Milshina, Natalia V and Mobarry, C and Morris, J and Moshrefi, A and Mount, S M and Moy, M and Murphy, B and Murphy, L and Muzny, D M and Nelson, D L and Nelson, D R and Nelson, K A and Nixon, K and Nusskern, D R and Pacleb, J M and Palazzolo, M and Pittman, G S and Pan, S and Pollard, J and Puri, V and Reese, M G and Reinert, Knut and Remington, K and Saunders, R D and Scheeler, F and Shen, H and Shue, Bixiong Chris and Sid{\'e}n-Kiamos, I and Simpson, Michael and Skupski, Marian and Smith, T and Spier, E and Spradling, A C and Stapleton, M and Strong, R and Sun, E and Svirskas, R and Tector, C and Turner, Russell and Venter, Eli and Wang, AH H and Wang, X and Wang, Z Y and Wassarman, D A and Weinstock, G M and Weissenbach, Jean and Williams, S M and WoodageT and Worley, K C and Wu, D and Yang, S and Yao, Q A and Ye, J and Yeh, R F and Zaveri, Jayshree S and Zhan, M and Zhang, G and Zhao, Q and Zheng, L and Zheng, X H and Zhong, F N and Zhong, Wenyan and Zhou, X J and Zhu, S and Zhu, X and Smith, Hamilton O and Gibbs, R A and Myers, Eugene W and Rubin, G M and Venter, J Craig},
title = {{The genome sequence of Drosophila melanogaster}},
journal = {Science (New York, NY)},
year = {2000},
volume = {287},
number = {5461},
pages = {2185--2195},
month = mar,
affiliation = {Celera Genomics, 45 West Gude Drive, Rockville, MD 20850, USA.},
doi = {10.1126/science.287.5461.2185},
pmid = {10731132},
language = {eng},
read = {Yes},
rating = {0},
date-added = {2008-10-31T11:55:23GMT},
date-modified = {2015-11-06T12:10:11GMT},
abstract = {The fly Drosophila melanogaster is one of the most intensively studied organisms in biology and serves as a model system for the investigation of many developmental and cellular processes common to higher eukaryotes, including humans. We have determined the nucleotide sequence of nearly all of the approximately 120-megabase euchromatic portion of the Drosophila genome using a whole-genome shotgun sequencing strategy supported by extensive clone-based sequence and a high-quality bacterial artificial chromosome physical map. Efforts are under way to close the remaining gaps; however, the sequence is of sufficient accuracy and contiguity to be declared substantially complete and to support an initial analysis of genome structure and preliminary gene annotation and interpretation. The genome encodes approximately 13,600 genes, somewhat fewer than the smaller Caenorhabditis elegans genome, but with comparable functional diversity.},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.287.5461.2185},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2000/Brandon/Science%202000%20Brandon-2.pdf},
file = {{Science 2000 Brandon-2.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2000/Brandon/Science 2000 Brandon-2.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1126/science.287.5461.2185}}
}

@article{Lenhof:2000vd,
author = {Lenhof, Hans-Peter and Mehlhorn, K and Mutzel, P and Reinert, Knut},
title = {{A polyhedral approach to sequence alignment problems}},
journal = {Discrete Applied Mathematics},
year = {2000},
rating = {0},
date-added = {2008-10-31T11:59:48GMT},
date-modified = {2015-11-06T12:10:11GMT},
abstract = {[PDF]},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0166218X00001943},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2000/Lenhof/Discrete%20Applied%20Mathematics%202000%20Lenhof.pdf},
file = {{Discrete Applied Mathematics 2000 Lenhof.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2000/Lenhof/Discrete Applied Mathematics 2000 Lenhof.pdf:application/pdf}},
uri = {\url{papers3://publication/uuid/8E7BD74A-0AF4-4CEE-A607-0C118C7B4B70}}
}

@article{Reinert:2000wpa,
author = {Reinert, Knut and Stoye, Jens and Will, T},
title = {{An iterative method for faster sum-of-pairs multiple sequence alignment}},
journal = {Bioinformatics (Oxford, England)},
year = {2000},
rating = {0},
date-added = {2015-09-08T22:50:18GMT},
date-modified = {2015-11-26T15:38:49GMT},
abstract = {Abstract Motivation: Multiple sequence alignment is an important tool in computational biology. In order to solve the task of computing multiple alignments in affordable time, the most commonly used multiple alignment methods have to use heuristics. Nevertheless, ... 
},
url = {http://bioinformatics.oxfordjournals.org/content/16/9/808.short},
uri = {\url{papers3://publication/uuid/5A148A39-0A2E-4EB4-BF78-D3A7BBD7933B}}
}

@article{Pan:2000tj,
author = {Pan, S and Pollard, J and Puri, V and Reese, M G and Reinert, Knut},
title = {{The genome sequence of Drosophila melanogaster}},
journal = {Science (New York, NY)},
year = {2000},
rating = {0},
date-added = {2015-09-08T22:50:14GMT},
date-modified = {2015-11-26T15:38:49GMT},
abstract = {Abstract The fly Drosophila melanogaster is one of the most intensively studied organisms in biology and serves as a model system for the investigation of many developmental and cellular processes common to higher eukaryotes, including humans. We have determined ... 
},
url = {http://www.sciencemag.org/content/287/5461/2185.short},
uri = {\url{papers3://publication/uuid/33489D28-2153-4A6A-AD38-625A35ED99E4}}
}

@article{Lermen:2000dl,
author = {Lermen, M and Reinert, Knut},
title = {{The practical use of the A* algorithm for exact multiple sequence alignment}},
journal = {Journal of computational biology : a journal of computational molecular cell biology},
year = {2000},
volume = {7},
number = {5},
pages = {655--671},
affiliation = {Max Planck Institut f{\"u}r Informatik, Im Stadtwald, D-66123 Saarbr{\"u}cken, Germany.},
doi = {10.1089/106652701446134},
pmid = {11153092},
language = {eng},
read = {Yes},
rating = {0},
date-added = {2008-10-31T11:53:25GMT},
date-modified = {2015-11-06T12:10:11GMT},
abstract = {Multiple alignment is an important problem in computational biology. It is well known that it can be solved exactly by a dynamic programming algorithm which in turn can be interpreted as a shortest path computation in a directed acyclic graph. The A* algorithm (or goal-directed unidirectional search) is a technique that speeds up the computation of a shortest path by transforming the edge lengths without losing the optimality of the shortest path. We implemented the A* algorithm in a computer program similar to MSA (Gupta et al., 1995) and FMA (Shibuya and Imai, 1997). We incorporated in this program new bounding strategies for both lower and upper bounds and show that the A* algorithm, together with our improvements, can speed up computations considerably. Additionally, we show that the A* algorithm together with a standard bounding technique is superior to the well-known Carrillo-Lipman bounding since it excludes more nodes from consideration.},
url = {http://www.liebertonline.com/doi/abs/10.1089%2F106652701446134},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2000/Lermen/J%20Comput%20Biol%202000%20Lermen.pdf},
file = {{J Comput Biol 2000 Lermen.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2000/Lermen/J Comput Biol 2000 Lermen.pdf:application/pdf;J Comput Biol 2000 Lermen.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2000/Lermen/J Comput Biol 2000 Lermen.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1089/106652701446134}}
}

@article{Lenhof:1999vj,
author = {Lenhof, Hans-Peter and Morgenstern, Burkhard and Reinert, Knut},
title = {{An exact solution for the segment-to-segment multiple sequence alignment problem}},
journal = {Bioinformatics (Oxford, England)},
year = {1999},
volume = {15},
number = {3},
pages = {203--210},
month = feb,
affiliation = {MPI f{\"u}r Informatik, Im Stadtwald, 66123 Saarbr{\"u}cken, Germany.},
pmid = {10222407},
language = {eng},
read = {Yes},
rating = {0},
date-added = {2008-10-31T11:50:33GMT},
date-modified = {2015-11-06T12:10:11GMT},
abstract = {MOTIVATION: In molecular biology, sequence alignment is a crucial tool in studying the structure and function of molecules, as well as the evolution of species. In the segment-to-segment variation of the multiple alignment problem, the input can be seen as a set of non-gapped segment pairs (diagonals). Given a weight function that assigns a weight score to every possible diagonal, the goal is to choose a consistent set of diagonals of maximum weight. We show that the segment-to-segment multiple alignment problem is equivalent to a novel formulation of the Maximum Trace problem: the Generalized Maximum Trace (GMT) problem. Solving this problem to optimality, therefore, may improve upon the previous greedy strategies that are used for solving the segment-to-segment multiple sequence alignment problem. We show that the GMT can be stated in terms of an integer linear program and then solve the integer linear program using methods from polyhedral combinatorics. This leads to a branch-and-cut algorithm for segment-to-segment multiple sequence alignment. RESULTS: We report on our first computational experiences with this novel method and show that the program is able to find optimal solutions for real-world test examples.},
url = {http://bioinformatics.oxfordjournals.org/cgi/reprint/15/3/203},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/1999/Lenhof/Bioinformatics%201999%20Lenhof.pdf},
file = {{Bioinformatics 1999 Lenhof.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/1999/Lenhof/Bioinformatics 1999 Lenhof.pdf:application/pdf}},
uri = {\url{papers3://publication/uuid/D6134EF0-63C7-404D-ADB3-C453BCBAC15D}}
}

@phdthesis{Reinert1999,
author = {Reinert, Knut},
title = {{A polyhedral approach to sequence alignment problems}},
school = {Universit{\"a}t Saarbr{\"u}cken},
year = {1999},
publisher = {Universit{\"a}t Saarbr{\"u}cken},
rating = {0},
date-added = {2013-09-04T14:04:09GMT},
date-modified = {2015-07-12T09:51:09GMT},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Books/1999/Reinert/1999%20Reinert.pdf},
file = {{1999 Reinert.pdf:/Users/reinert/Dropbox/Library.papers3/Books/1999/Reinert/1999 Reinert.pdf:application/pdf}},
uri = {\url{papers3://publication/uuid/9CBE6F0B-3A75-4E5C-9112-470E71E0F3EC}}
}

@article{Lenhof:1998vl,
author = {Lenhof, H P and Reinert, Knut and Vingron, Martin},
title = {{A polyhedral approach to RNA sequence structure alignment.}},
journal = {Journal of computational biology : a journal of computational molecular cell biology},
year = {1998},
volume = {5},
number = {3},
pages = {517--530},
affiliation = {MPI f{\"u}r Informatik, Saarbr{\"u}cken, Germany.},
pmid = {9773347},
language = {English},
read = {Yes},
rating = {0},
date-added = {2008-10-31T11:52:08GMT},
date-modified = {2015-11-06T12:10:11GMT},
abstract = {Ribonucleic acid (RNA) is a polymer composed of four bases denoted A, C, G, and U. It generally is a single-stranded molecule where the bases form hydrogen bonds within the same molecule leading to structure formation. In comparing different homologous RNA molecules it is important to consider both the base sequence and the structure of the molecules. Traditional alignment algorithms can only account for the sequence of bases, but not for the base pairings. Considering the structure leads to significant computational problems because of the dependencies introduced by the base pairings. In this paper we address the problem of optimally aligning a given RNA sequence of unknown structure to one of known sequence and structure. We phrase the problem as an integer linear program and then solve it using methods from polyhedral combinatorics. In our computational experiments we could solve large problem instances--23S ribosomal RNA with more than 1400 bases--a size intractable for former algorithms.},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=9773347&retmode=ref&cmd=prlinks},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/1998/Lenhof/J%20Comput%20Biol%201998%20Lenhof.pdf},
file = {{J Comput Biol 1998 Lenhof.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/1998/Lenhof/J Comput Biol 1998 Lenhof.pdf:application/pdf;J Comput Biol 1998 Lenhof.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/1998/Lenhof/J Comput Biol 1998 Lenhof.pdf:application/pdf}},
uri = {\url{papers3://publication/uuid/F1076CD6-B1BB-4951-B9CA-FDD79D3B2B5E}}
}

@inproceedings{Reinert:1997wq,
author = {Reinert, Knut and Lenhof, H P and Mutzel, P and Mehlhorn, K},
title = {{A branch-and-cut algorithm for multiple sequence alignment}},
booktitle = {Proceedings of the first {\ldots}},
year = {1997},
rating = {0},
date-added = {2015-09-08T22:50:19GMT},
date-modified = {2015-11-26T15:38:49GMT},
abstract = {Abstract Multiple ht{\textasciitilde} lucnce alignment is an important, problem in computatiorml biology. We study t, hr Maximum'['race formulation introduced by Kecrciog111 [K{\&}31]. We first phrasr the problenl in terms of forbidden subgraphs, which enables us to cxprcss Maximum Trace as ... 
},
url = {http://dl.acm.org/citation.cfm?id=267845},
uri = {\url{papers3://publication/uuid/0CC0DB20-40FF-4C84-A25A-318471B000BD}}
}

@article{Bradford:1996tk,
author = {Reinert, Knut},
title = {{Lower bounds for row minima searching}},
journal = {Automata},
year = {1996},
read = {Yes},
rating = {0},
date-added = {2010-06-24T09:51:00GMT},
date-modified = {2015-11-06T12:10:15GMT},
abstract = {Finding the row minima (maxima) of monotone matrices was introduced by Ag- garwal, Klawe, Moran, Shor, and Wilber [1]. They also gave an asymptotically optimal sequential algorithm for finding the row minima in totally monotone matrices, among other things. Row minima },
url = {http://www.springerlink.com/index/y6mj13212648p112.pdf},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/1996/Reinert/Automata%201996%20Reinert.pdf},
file = {{Automata 1996 Reinert.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/1996/Reinert/Automata 1996 Reinert.pdf:application/pdf}},
uri = {\url{papers3://publication/uuid/60AFB587-8469-495C-9F3C-B58DA3304D04}}
}

