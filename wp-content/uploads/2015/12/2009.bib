%% Created using Papers on Fri, 18 Dec 2015.
%% http://papersapp.com/papers/

@book{GogolDoring:2009wx,
author = {Gogol-D{\"o}ring, Andreas and Reinert, Knut},
title = {{Biological sequence analysis using the SeqAn C++ library}},
publisher = {CRC},
year = {2009},
month = oct,
isbn = {9781420076233},
language = {English},
rating = {0},
date-added = {2011-06-08T20:46:19GMT},
date-modified = {2015-11-06T12:10:05GMT},
abstract = {A key to that invaluable resource, this book provides a highly accessible way for the rapid prototyping of algorithms in the field.},
url = {http://books.google.com/books?hl=en&lr=&id=Qf98t1LOiBYC&oi=fnd&pg=PP1&dq=seqan+reinert&ots=4y9iyK_zEv&sig=P6EZHMUrqI1Czy6VqcwgIr4qPBg},
uri = {\url{papers3://publication/uuid/E63A4075-298E-4848-908E-DD78EAB143E5}}
}

@article{Weese:2009iw,
author = {Weese, David and Emde, A and Rausch, T and D{\"o}ring, Andreas and Reinert, Knut},
title = {{RazerS--fast read mapping with sensitivity control.}},
journal = {Genome research},
year = {2009},
volume = {19},
number = {9},
pages = {1646--1654},
month = sep,
affiliation = {Department of Computer Science, Free University of Berlin, 14195 Berlin, Germany. weese@inf.fu-berlin.de},
doi = {10.1101/gr.088823.108},
pmid = {19592482},
pmcid = {PMC2752123},
language = {English},
read = {Yes},
rating = {0},
date-added = {2009-08-14T13:54:02GMT},
date-modified = {2015-11-22T18:57:21GMT},
abstract = {Second-generation sequencing technologies deliver DNA sequence data at unprecedented high throughput. Common to most biological applications is a mapping of the reads to an almost identical or highly similar reference genome. Due to the large amounts of data, efficient algorithms and implementations are crucial for this task. We present an efficient read mapping tool called RazerS. It allows the user to align sequencing reads of arbitrary length using either the Hamming distance or the edit distance. Our tool can work either lossless or with a user-defined loss rate at higher speeds. Given the loss rate, we present an approach that guarantees not to lose more reads than specified. This enables the user to adapt to the problem at hand and provides a seamless tradeoff between sensitivity and running time.},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=19592482&retmode=ref&cmd=prlinks},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2009/Weese/Genome%20Res.%202009%20Weese.pdf},
file = {{Genome Res. 2009 Weese.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2009/Weese/Genome Res. 2009 Weese.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1101/gr.088823.108}}
}

@article{zerck_09_iterative,
author = {Zerck, Alexandra and Nordhoff, Eckhard and Resemann, Anja and Mirgorodskaya, Ekaterina and Suckau, Detlef and Reinert, Knut and Lehrach, Hans and Gobom, Johan},
title = {{An iterative strategy for precursor ion selection for LC - MS/MS based shotgun proteomics}},
journal = {Journal of Proteome Research},
year = {2009},
volume = {8},
number = {7},
pages = {3239--3251},
month = jul,
affiliation = {Max Planck Institute for Molecular Genetics, Department Vertebrate Genomics, Ihnestr. 63-73, D-14195 Berlin, Germany. zerck@molgen.mpg.de},
doi = {10.1021/pr800835x},
pmid = {19402737},
language = {English},
read = {Yes},
rating = {0},
date-added = {2009-08-14T13:55:08GMT},
date-modified = {2015-11-06T12:10:13GMT},
abstract = {Currently, the precursor ion selection strategies in LC-MS mainly choose the most prominent peptide signals for MS/MS analysis. Consequently, high-abundance proteins are identified by MS/MS of many peptides, whereas proteins of lower abundance might elude identification. We present a novel, iterative and result-driven approach for precursor ion selection that significantly increases the efficiency of an MS/MS analysis by decreasing data redundancy and analysis time. By simulating different strategies for precursor ion selection on an existing data set, we compare our method to existing result-driven strategies and evaluate its performance with regard to mass accuracy, database size, and sample complexity.},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=19402737&retmode=ref&cmd=prlinks},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2009/Zerck/J%20Proteome%20Res%202009%20Zerck.pdf},
file = {{J Proteome Res 2009 Zerck.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2009/Zerck/J Proteome Res 2009 Zerck.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1021/pr800835x}}
}

@article{Bauer:2009ji,
author = {Bauer, Raphael Andr{\'e} and Rother, Kristian and Moor, Peter and Reinert, Knut and Steinke, Thomas and Bujnicki, Janusz M and Preissner, Robert},
title = {{Fast Structural Alignment of Biomolecules Using a Hash Table, N-Grams and String Descriptors}},
journal = {Algorithms},
year = {2009},
volume = {2},
number = {2},
pages = {692--709},
month = jun,
publisher = {Molecular Diversity Preservation International},
doi = {10.3390/a2020692},
language = {English},
read = {Yes},
rating = {0},
date-added = {2011-06-08T20:48:18GMT},
date-modified = {2015-11-06T12:10:16GMT},
abstract = {This work presents a generalized approach for the fast structural alignment of thousands of macromolecular structures. The method uses string representations of a macromolecular structure and a hash table that stores n-grams of a certain size for searching. To this end, macromolecular structure-to-string translators were implemented for protein and RNA structures. A query against the index is performed in two hierarchical steps to unite speed and precision. In the first step the query structure is translated into n-grams, and all target structures containing these n-grams are retrieved from the hash table. In the second step all corresponding n-grams of the query and each target structure are subsequently aligned, and after each alignment a score is calculated based on the matching n-grams of query and target. The extendable framework enables the user to query and structurally align thousands of protein and RNA structures on a commodity machine and is available as open source from http://lajolla.sf.net.},
url = {http://www.mdpi.com/1999-4893/2/2/692/},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2009/Bauer/Algorithms%202009%20Bauer.pdf},
file = {{Algorithms 2009 Bauer.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2009/Bauer/Algorithms 2009 Bauer.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.3390/a2020692}}
}

@article{Rausch:2009hq,
author = {Rausch, T and Koren, Sergey and Denisov, G and Weese, David and Emde, A and D{\"o}ring, Andreas and Reinert, Knut},
title = {{A consistency-based consensus algorithm for de novo and reference-guided sequence assembly of short reads.}},
journal = {Bioinformatics (Oxford, England)},
year = {2009},
volume = {25},
number = {9},
pages = {1118--1124},
month = may,
affiliation = {International Max Planck Research School for Computational Biology and Scientific Computing, Ihnestr. 63-73, Algorithmische Bioinformatik, Institut f{\"u}r Informatik, Takustr. 9, 14195 Berlin, Germany. rausch@inf.fu-berlin.de},
doi = {10.1093/bioinformatics/btp131},
pmid = {19269990},
pmcid = {PMC2732307},
language = {English},
read = {Yes},
rating = {0},
date-added = {2009-03-11T08:51:34GMT},
date-modified = {2015-11-06T12:10:12GMT},
abstract = {MOTIVATION:Novel high-throughput sequencing technologies pose new algorithmic challenges in handling massive amounts of short-read, high-coverage data. A robust and versatile consensus tool is of particular interest for such data since a sound multi-read alignment is a prerequisite for variation analyses, accurate genome assemblies and insert sequencing.

RESULTS:A multi-read alignment algorithm for de novo or reference-guided genome assembly is presented. The program identifies segments shared by multiple reads and then aligns these segments using a consistency-enhanced alignment graph. On real de novo sequencing data obtained from the newly established NCBI Short Read Archive, the program performs similarly in quality to other comparable programs. On more challenging simulated datasets for insert sequencing and variation analyses, our program outperforms the other tools.

AVAILABILITY:The consensus program can be downloaded from https://www.seqan.de/projects/consensus.html. It can be used stand-alone or in conjunction with the Celera Assembler. Both application scenarios as well as the usage of the tool are described in the documentation.},
url = {http://bioinformatics.oxfordjournals.org/cgi/content/short/25/9/1118},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2009/Rausch/Bioinformatics%202009%20Rausch.pdf},
file = {{Bioinformatics 2009 Rausch.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2009/Rausch/Bioinformatics 2009 Rausch.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1093/bioinformatics/btp131}}
}

@article{Lenhof:2009bq,
author = {Lenhof, Hans-Peter and Reinert, Knut and Vingron, Martin},
title = {{A Polyhedral Approach to RNA Sequence Structure Alignment}},
journal = {dx.doi.org},
year = {2009},
volume = {5},
number = {3},
pages = {517--530},
month = mar,
doi = {10.1089/cmb.1998.5.517},
language = {English},
rating = {0},
date-added = {2015-09-08T22:50:19GMT},
date-modified = {2015-11-26T15:38:49GMT},
abstract = {ABSTRACT Ribonucleic acid (RNA) is a polymer composed of four bases denoted A, C, G, and U. It generally is a single-stranded molecule where the bases form hydrogen bonds within the same molecule leading to structure formation. In comparing different homologous RNA molecules it is important to consider both the base sequence and the structure of the molecules. Traditional alignment algorithms can only account for the sequence of bases, but not for the base pairings. Considering the structure leads to significant computational problems because of the dependencies introduced by the base pairings. In this paper we address the problem of optimally aligning a given RNA sequence of unknown structure to one of known sequence and structure. We phrase the problem as an integer linear program and then solve it using methods from polyhedral combinatorics. In our computational experiments we could solve large problem instances{\textemdash}23S ribosomal RNA with more than 1400 bases{\textemdash}a size intractable for former algorithms.},
url = {http://www.liebertonline.com/doi/abs/10.1089/cmb.1998.5.517},
uri = {\url{papers3://publication/doi/10.1089/cmb.1998.5.517}}
}

@incollection{Rausch2009,
author = {Rausch, T and Reinert, Knut},
title = {{The problem solving handbook for computational biology and bioinformatics}},
year = {2009},
editor = {Heath, L S and Ramakrishnan, N},
publisher = {Springer},
rating = {0},
date-added = {2013-09-04T14:04:09GMT},
date-modified = {2015-07-12T09:51:09GMT},
uri = {\url{papers3://publication/uuid/A9C736AD-428B-4BD0-9E47-9FEBC190E3A9}}
}

@article{SchulzTrieglaff:2009cq,
author = {Schulz-Trieglaff, Ole and Machtejevas, Egidijus and Reinert, Knut and Schl{\"u}ter, Hartmut and Thiemann, Joachim and Unger, Klaus},
title = {{Statistical quality assessment and outlier detection for liquid chromatography-mass spectrometry experiments.}},
journal = {BioData mining},
year = {2009},
volume = {2},
number = {1},
pages = {4},
affiliation = {International Max Planck Research School for Computational Biology and Scientific Computing, Berlin, Germany. trieglaf@inf.fu-berlin.de},
doi = {10.1186/1756-0381-2-4},
pmid = {19351414},
pmcid = {PMC2678124},
language = {English},
read = {Yes},
rating = {0},
date-added = {2009-06-22T07:13:38GMT},
date-modified = {2015-11-06T12:10:13GMT},
abstract = {BACKGROUND:Quality assessment methods, that are common place in engineering and industrial production, are not widely spread in large-scale proteomics experiments. But modern technologies such as Multi-Dimensional Liquid Chromatography coupled to Mass Spectrometry (LC-MS) produce large quantities of proteomic data. These data are prone to measurement errors and reproducibility problems such that an automatic quality assessment and control become increasingly important.

RESULTS:We propose a methodology to assess the quality and reproducibility of data generated in quantitative LC-MS experiments. We introduce quality descriptors that capture different aspects of the quality and reproducibility of LC-MS data sets. Our method is based on the Mahalanobis distance and a robust Principal Component Analysis.

CONCLUSION:We evaluate our approach on several data sets of different complexities and show that we are able to precisely detect LC-MS runs of poor signal quality in large-scale studies.},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=19351414&retmode=ref&cmd=prlinks},
local-url = {file://localhost/Users/reinert/Dropbox/Library.papers3/Articles/2009/Schulz-Trieglaff/BioData%20Min%202009%20Schulz-Trieglaff.pdf},
file = {{BioData Min 2009 Schulz-Trieglaff.pdf:/Users/reinert/Dropbox/Library.papers3/Articles/2009/Schulz-Trieglaff/BioData Min 2009 Schulz-Trieglaff.pdf:application/pdf}},
uri = {\url{papers3://publication/doi/10.1186/1756-0381-2-4}}
}

@incollection{Rausch2009,
author = {Rausch, T and Reinert, Knut},
title = {{The problem solving handbook for computational biology and bioinformatics}},
year = {2009},
editor = {Heath, L S and Ramakrishnan, N},
publisher = {Springer},
rating = {0},
date-added = {2013-09-13T13:08:27GMT},
date-modified = {2015-07-12T09:51:09GMT},
uri = {\url{papers3://publication/uuid/82E8C1CD-703D-440D-AA9B-A302D066BBFC}}
}

@article{Emde:2009wq,
author = {Emde, A and Rausch, T and D{\"o}ring, Andreas and Reinert, Knut},
title = {{RazerS{\textemdash}fast read mapping with sensitivity control}},
journal = {Genome {\ldots}},
year = {2009},
rating = {0},
date-added = {2015-09-08T22:50:00GMT},
date-modified = {2015-11-26T15:38:49GMT},
abstract = {Abstract Second-generation sequencing technologies deliver DNA sequence data at unprecedented high throughput. Common to most biological applications is a mapping of the reads to an almost identical or highly similar reference genome. Due to the large ... 
},
url = {http://genome.cshlp.org/content/19/9/1646.short},
uri = {\url{papers3://publication/uuid/FF1EEB49-88E0-4C15-B291-F9A5F896E20C}}
}

@article{Ponten:2009wf,
author = {Ponten, F and Radbruch, A and Reinert, Knut},
title = {{Approaching clinical proteomics: current state and future fields of application in fluid proteomics}},
journal = {Clinical Chemistry and {\ldots}},
year = {2009},
rating = {0},
date-added = {2015-09-08T22:50:01GMT},
date-modified = {2015-11-26T15:38:49GMT},
abstract = {Abstract The field of clinical proteomics offers opportunities to identify new disease biomarkers in body fluids, cells and tissues. These biomarkers can be used in clinical applications for diagnosis, stratification of patients for specific treatment, or therapy ... 
},
url = {http://www.degruyter.com/view/j/cclm.2009.47.issue-6/cclm.2009.167/cclm.2009.167.xml},
uri = {\url{papers3://publication/uuid/87075DA1-B616-4AD8-BCC5-3C2858BF3228}}
}